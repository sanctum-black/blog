<article class="first">
  <div class="title">
    <h1>10 Advanced Programming Techniques</h1>
  </div>
</article>

---

[![made-with badge](https://img.shields.io/static/v1?label=Made%20with&message=Obsidian&color=7d5bed&logo=obsidian&labelColor=1a1a1a&style=flat)](https://obsidian.md/)

[![type](https://img.shields.io/static/v1?label=Type&message=blog&color=e60048&logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAYAAAByDd+UAAAAi0lEQVRIS+2WMQ7AIAhF/UNXrtP7rz2OYxeqTWxMTBUSxQVXfnzyQQKC8YExL7zAGCNbgIkIsIKVhBw4vbR7unR6Gp0LvwxXd2v+EvkdDpxWXpWlRTyi9/pABRyBJHEHSlxSadxSlV0SsVsqcUml2W/pynWxnsXNisHMRxrCl8qvH3ECnQDuOmy+0zwB4WNxmUKgwwAAAABJRU5ErkJggg==&labelColor=1a1a1a&style=flat)](https://pabloagn.com/blog/) [![category](https://img.shields.io/static/v1?label=Category&message=computer-science&color=e60048&logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAYAAAByDd+UAAAB9UlEQVRIS6VWMU7DQBDkDAQEdrAoCISCAomCL1DxC95Azy9oeQS/oOIHVFAgREFoCHGCRSzZzEU+63LZ9W6CO/vudmZ2d9Zn1pTPaDSqut2usduHw+FpFEUv7t1fk8LNAkiPDWj3+ADuTPjNvXMxWwGzLCuqqtqwh5MkiY0xEwfOAfrEKFAWUBO4DZQDXgCEqjuouvbZUanUrocpngMMVUkKtKC+WhFQUudAUd8r1PkepJ/w7Tysn4uzkNJlascF9WOASAki6w0xrn19b3Gpps5y3kRfJADPZgr9gJSP0EgDHDiQ/Mp50PfxAmDtuQhsZmb/z0OVhwSkmGrSGp5bGRDp3EFaJ5JaiahdZ2vYNj/JkWVMgW7sgNw2yOW+99gacp7TeFE72OcUrgo4Ho93+/3+D5T9QmGHm0BNSnHgMI7jj9Ai2tElZGCK9S3S+GA4BcNNydBaIuEstu/iLJWCa+pLDm+Nz+xQAsBenucnRVG8asFq0s/Yf9YoVAI21wyn3N4I7M1A8ijWHwB42XrFqIO9YfMRlVqqyXC5ukED3nIEVJcoBXv1lmWa5gIpeeQioyTWVj1uXf0DpgKUZbmfpunXKnVnU9rWDKiTHRSDNkDu36iqIQK/Q+mxU8sBYniL/1EVoJ9Wqwo/5x6Cf9YKv6Em1XbNH5bGfSwvuRe1AAAAAElFTkSuQmCC&labelColor=1a1a1a&style=flat)](https://pabloagn.com/categories/computer-science/) [![technologies](https://img.shields.io/static/v1?label=Technologies&message=Python&color=e60048&logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA4AAAAOCAYAAAAfSC3RAAAACXBIWXMAAAsTAAALEwEAmpwYAAAA1klEQVR4nM2RMW7CUBBEnUikIQUIlBJxrrQgJG7ABRBnoUkaWhpoUgWJlgNYbvz/G1dUi1ayoy87rpOtVrszs6OdLPtXlef5UNJXjHHcCwohjMzsKZ3FGN+Bq/e+c0xHGfiWtEznkg6SNnW/dIxjs0YJ2AMnM3tJSFPgHkKY17gBcAQ+zOw5A3aSbsCkdW0NnNOZY2rstpcInJ3cS/SzwGdqtSzLmdusquqtIXWsehVF8QpcJK1qmxt/TMv6wjE/z0leP27i8Ag8inT/axxtAQ+9o/zn9QD3JOiyTjnQEQAAAABJRU5ErkJggg==&labelColor=1a1a1a&style=flat)](https://pabloagn.com/technologies/) [![website article](https://img.shields.io/static/v1?label=Website&message=Post%20Link&color=e60048&logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAYAAAByDd+UAAAACXBIWXMAAAsTAAALEwEAmpwYAAAB+ElEQVR4nO2VOYgUURCGR/BAI4MN1EwjI89EMDYQvNBNNNlcE0VBUdlUUSMjj2BF2UDRePDAwGzNF2GNPIYd8Hjv/6YnEHSf/FIDPTJiu4nJFBTd1Kv6/nrVBd1q/S8DJiU9AmaBm5LOSjoATPwDY0LSQUnnzDArmJOjkqclvQceSHohaR6oJC1JeiPprqT9pZSVg5pSyirH4sw5S1EzbwZwP5jTIwWBdj1meEppZ6/XOyXpCdCX9Am4Fv45Yo+Bk1VV7ag3FNz2kKC7yznvHiX4u3U6nXU55xPAW7vfHfvLmNtmW8NaFux67k0Ea03esTfJJQTj23bHgiNtPNK6jZem3Wpg46Wp23hp2q0GNl6axksjaRGYkXRF0mnHq6ra2HSk/X5/k6RDks6YEazFPwnuBS5KuirptqTnkj4CJZ4zwNFSytqBoP/2wDHgXi33A/BM0i2zzDR7SBC4LGlPr9fb5huVUlYMus45b5E0FYJfgQS8C8/Al7jJVEpp86DODLPMNDs0up7xXBQZVKLLb8CCpIfA+ZzzvpTS+lLKGuAI8DT8cClltc+c49yoWQjGL140ao25oW8QXW1IKe3KOR8Hbkh66ZtI+i7plaG+iR244JjP3HDkXnetGWbVp9XYopHtHgvwWtIPu9+BSx7bssBNDdhqX07xT/Jbz1SBBDGHAAAAAElFTkSuQmCC&labelColor=1a1a1a&style=flat)](https://pabloagn.com/blog/programming-best-practices-writing-better-code/)

We could spend our entire developer's life using just the basic concepts of any programming language we choose to learn, and there's nothing wrong with that; in many cases, very powerful concepts have already been abstracted for us, providing a great out-of-the-box experience, particularly with languages such as Python, R and JavaScript. However, a programmer's horizon would be limited if we didn't have advanced techniques to play with, because in the end, programming is about solving problems, and the more creative, the better. These techniques are not only there to make us more efficient in writing code, but also in thinking out of the box by using more sophisticated tools.

In this Blog Article, we'll discuss 10 advanced programming techniques that provide different functionalities to our code; they can make our syntax more elegant, expressive, performant, compact, modular, and a bunch of different attributes that we probably didn't know could be included in the first place. We'll focus on Scala since many of the techniques are closely related with functional programming.

We'll start by providing historical context on each technique, following a formal definition, main advantages, a set of hands-on examples, recommendations & best practices, and popular real-world use-cases.

We'll be using Scala scripts which can be found in the [Blog Article Repo](https://github.com/pabloagn/blog/tree/master/computer-science/10-advanced-programming-techniques).

---

# Table of Contents
- [What to expect](#what-to-expect)
- Preparing our environment
- Tail recursion
	- Definition
	- Advantages
	- Examples
		- Sum of a list
		- Factorial calculation
		- Fibonacci sequence
		- Exponentiation
	- Recommendations & best practices
	- Use cases
- Higher-order functions
	- Definition
	- Advantages
	- Examples
		- Single verification of a list
		- Variation of a summation
	- Recommendations & best practices
	- Use cases
- Currying
	- Definition
	- Advantages
	- Examples
		- A curried addition function
		- A curried call using two functions
	- Recommendations & best practices
	- Use cases
- Monads
	- Definition
	- Advantages
	- Examples
		- An undefined operation
	- Recommendations & best practices
	- Use cases
- Pattern matching and extractors
	- Definition
	- Advantages
	- Examples
		- Handling an undefined operation
	- Recommendations & best practices
	- Use cases
- Lazy evaluation
	- Definition
	- Advantages
	- Examples
		- 
	- Recommendations & best practices
	- Use cases
- Implicits and type classes
	- Definition
	- Advantages
	- Examples
		- 
	- Recommendations & best practices
	- Use cases
- Continuation-passing style (CPS)
	- Definition
	- Advantages
	- Examples
	- Recommendations & best practices
	- Use cases
- Macros and metaprogramming
	- Definition
	- Advantages
	- Examples
	- Recommendations & best practices
	- Use cases
- Higher-kinded types
	- Definition
	- Advantages
	- Examples
	- Recommendations & best practices
	- Use cases
- Next steps
- [Conclusions](#conclusions)
- [References](#references)
- [Copyright](#copyright)

---

# What to expect
There are simple techniques such as code refactoring, modularization, and anonymous functions we can use to instantly make our code better. However, this segment will introduce advanced programming concepts. Consequently, it'll be best if we already have some previous knowledge of functional programming and ideally, Scala, Haskell, or a similar language.

We will not include any installation process for Scala neither for Python, since this is out of the scope of this segment (*a full Scala 3 installation along with sbt and a preferred IDE is assumed*). We will also not discuss basic principles such as syntax and compiling, since this is also out of the scope of this segment. Instead, we'll introduce 10 techniques and explain why they're useful, go over each one in detail, provide a set of examples in Scala & Python, depending on the implementation, and provide some recommendations for using each technique, as well as use-cases and best practices.

---

# Preparing our environment
As mentioned, we'll be using Scala for this segment.

We'll first head to the directory where we wish our project to be created in:

##### **Code**
```PowerShell
cd Projects
```

We'll then create a new Scala project by executing the following command in our terminal:

##### **Code**
```PowerShell
sbt new sbt/scala-seed.g8
```

We'll name our project whenever sbt requests the project name.

We'll then open our preferred IDE, import the newly-generated build, and create a new worksheet inside `/projectname/src/main/scala`

##### **Code**
```PowerShell
cd /projectname/src/main/scala
```

##### **Code**
```PowerShell
New-Item -ItemType File -Path ".\Sheet.worksheet.sc"
```

We'll mainly be working in our worksheet. However all the implementations discussed in this segment can also be included in a `.scala` file, given that we include the main Object and the main function inside a `Main.scala` file, where `Main` can be any name. 

Now that we have everything ready, we'll move to the first technique: Tail recursion.

---

# Tail recursion
The idea of **tail recursion** has been around for a long time, but its specific use in functional programming is often credited to the computer scientist Daniel P. Friedman and his colleagues.

In the late 1970s and early 1980s, Friedman and his colleagues developed a series of programming languages based on Scheme, a dialect of Lisp. These languages included a number of advanced features for functional programming, including tail recursion optimization.

## 1. Definition
Tail recursion is a recursive technique where the recursive call is the last operation performed in the function.

This means that the function's stack frame can be reused for the next recursive call, rather than creating a new stack frame for each recursive call; in simpler terms, the function's stack size remains constant and does not grow with each recursive call, even if the function recurses deeply.

## 2. Advantages
Overall, a recursive approach is more elegant and often times used to simplify complex problems. It also supports the idea of immutability (*variables do not change value at any time*), and is generally optimal for helping facilitate modular design by breaking a complex problem into smaller sub-problems.

More specifically, tail recursion implements a safer way to perform recursion; it avoids the potential of stack overflow errors by keeping the stack as constant. This means that we can solve big problems without exceeding maximum recursion depths and/or getting memory errors. 

## 3. Examples
Let us design 4 tail-recursive implementations, starting with the simpler ones. In every case, we will include a special annotation, `@tailrec`. This annotation ensures that the compiler optimizes our recursive implementation as a tail recursion problem.

It also explicitly tells the reader that our implementation is a tail-recursive one, and should be treated as such *(its important to note that the Scala compiler will most probably treat our function as tail-recursive even if we omit the annotation. The annotation just makes it explicit and ensures that the function is optimized for this end)*.

### 3.1 Sum of a list
Let us implement a tail-recursive function that calculates the sum of all elements in a given list of integers. The function should take a list as input and return the total sum of its elements.

What we'll do here, is the following:
1. Import the `tailrec` annotation.
2. Define two functions:
	- The first outer function will accept a list as its only input.
	- The second nested function will accept our list and a counter that we will use to keep track of the summation.
3. Call our outer function with a list.

We first import the `tailrec` annotation, and define our outer and nested recursive functions:

##### **Code**
```Scala
import scala.annotation.tailrec

def recursiveSum(list: List[Int]): Int = {
    @tailrec
    def sumItems(list: List[Int], counter: Int): Int = {
        if (list.isEmpty) counter
        else sumItems(list.tail, counter + list.head)
    }
    sumItems(list, 0)
}
```

If we noticed, the `@tailrec` annotation is referring to the nested function. This is because the outer function is not a tail-recursive function. In fact, it's not even a recursive function; it simply calls the nested function when called.

We can then call out outer function with a simple list first:

##### **Code**
```Scala
recursiveSum(List(1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
```

##### **Output**
```
// res1: Int = 55
```

We can try our function with a larger number:

##### **Code**
```Scala
recursiveSum(List.range(1, 100000))
```

##### **Output**
```
// res2: Int = 704982704
```

But what if we try it with an even larger number?:

##### **Code**
```Scala
recursiveSum(List.range(1, 1000000000))
```

##### **Output**
```
java.lang.OutOfMemoryError: Java heap space: failed reallocation of scalar replaced objects
```

In this case, we get a heap memory error. But didn't we just say that tail recursion maintained stacks as constant, meaning we should not have recursion depth errors? Yes, that's right, but the problem here is not a stack overflow error.

When we encounter a large list such as the one we defined in our last example, the compiler may have trouble allocating space for the object. While using tail recursion can help avoid stack overflow errors, it doesn't necessarily prevent memory heap errors; in some cases, a tail-recursive function may still consume a large amount of memory if it creates many intermediate objects that are not garbage collected.

We can see that although extremely useful, tail recursion has limitations. This can be solved by implementing other techniques:
- Processing the list in smaller chunks.
- Using lazy evaluation.
- Use primitive types.

### 3.2 Factorial calculation
Let us implement a tail-recursive function that calculates the factorial of a given non-negative integer $n$. The factorial of $n$ (*denoted as $n!$*) is the product of all positive integers less than or equal to $n$. For example, $5! = 5 × 4 × 3 × 2 × 1 = 120$.

The main problem with a factorial calculation, is that it grows fast. In fact, a factorial will eventually grow faster than $2^{n}$ and $e^{n}$ (*but not $n^n$*), so we have to find another numeric type that will allow us to store big integers; if we select the conventional `Int` type, the type will overflow and result in negative values, or in our case, 0.

As with the previous example, we will import the `@tailrec` annotation, and define two functions:
1. Import the `tailrec` annotation.
2. Define two functions:
	- The first outer function will accept an `Int` type as its only input.
	- The second nested function will accept our `Int` type value, and a counter with `BigInt` type that we'll use to keep track of the factorial operation.
3. Call our outer function with an integer value.

We first import the `tailrec` annotation, and define our outer and nested recursive functions:

##### **Code**
```Scala
def factorialCalc(n: Int): BigInt = {
    @tailrec
    def factorialItems(n: Int, counter: BigInt): BigInt = {
        if (n == 0) 1
        else if (n == 1) counter
        else factorialItems(n-1, n * counter)
    }
    factorialItems(n, 1)
}
```

We can start by calling our function using an edge case, which in our case will be 0:

##### **Code**
```Scala
factorialCalc(0)
```

##### **Output**
```
// res1: BigInt = 1
```

We can then call out outer function with a small integer:

##### **Code**
```Scala
factorialCalc(4)
```

##### **Output**
```
// res2: BigInt = 24
```

We can try our function with a larger number:

##### **Code**
```Scala
factorialCalc(10)
```

##### **Output**
```
// res3: BigInt = 3628800
```

And even with a larger number:

##### **Code**
```Scala
factorialCalc(100)
```

##### **Output**
```
// res4: BigInt = 93326215443944152681699238856266700490715968264381621468592963895217599993229915608941463976156518286253697920827223758251185210916864000000000000000000000000
```

We can see that the last output doesn't even fit in a single line. If we had not used `BigInt`, we would've gotten a type overflow.

### 3.3 Fibonacci sequence
Let us implement a tail-recursive function that returns the $n^{th}$ number in the Fibonacci sequence. The Fibonacci sequence is a series of numbers in which each number is the sum of the two preceding ones, starting from $0$ and $1$. For example, the sequence goes: $0, 1, 1, 2, 3, 5, 8, 13$, and so on.

Similar to our previous examples, we will proceed as follows:
1. Import the `tailrec` annotation.
2. Define two functions:
	- The first outer function will accept an `Int` type as its only input.
	- The second nested function will accept our `Int` type value, a number `next` with `BigInt` type, and a number `current` with `BigInt` type.
3. Call our outer function with an integer value.

We define a and b as follows:
- `next`: Will be the previous number in our sequence.
- `curr`: Will be the current number in our sequence.

We first import the `tailrec` annotation, and define our outer and nested recursive functions:

##### **Code**
```Scala
def FibCalc(n: Int): BigInt = {
    @tailrec
    def fibItems(n: Int, next: BigInt, current: BigInt): BigInt = {
        if (n == 0) current
        else fibItems(n-1, next + current, next)
    }
    fibItems(n, 1, 0)
}
```

Let us exemplify this calculation using a table:

| Index | Next                | Current      |
| ----- | ------------------- | --------- |
| 7     | 1                   | 0         |
| 6     | 1 (`next` + `current`)  | 1 (`next`)  |
| 5     | 2 (`next` + `current`)  | 1 (`next`)  |
| 4     | 3 (`next` + `current`)  | 2 (`next`)  |
| 3     | 5 (`next` + `current`)  | 3 (`next`)  |
| 2     | 8 (`next` + `current`)  | 5 (`next`)  |
| 1     | 13 (`next` + `current`) | 8 (`next`)  |
| 0     | 21 (`next` + `current`) | 13 (`next`) |

###### Table N: Tail-Recursive Fibonacci Sequence For Index = 7

A step-by-step explanation:
1. At first, we initialize our index with 7, our `next` value with 1, and our `current` value with 0.
2. We then subtract one from our index, set our new `next` to `next` + `current`, and set our new `current` to `next`.
3. We do this until our index is 0.
4. We finally return `current` as our final value.

What we're doing here is keeping track of three sequences at the same time:
- A decreasing sequence (`index`).
- An increasing sequence (`current`).
- The calculation (`next`).

The key thing here, is that we don't return the `next` value; instead, we return the `current` value, which is the `next` value from the previous step.

We can test our algorithm with some smaller and bigger numbers:

##### **Code**
```Scala
// Edge case call
FibCalc(0)

// Small integer call
FibCalc(5)

// Extense call
FibCalc(10)

// Even bigger call
FibCalc(1000)
```

##### **Output**
```
// res6: BigInt = 0

// res7: BigInt = 5

// res8: BigInt = 55

// res9: BigInt = 43466557686937456435688527675040625802564660517371780402481729089536555417949051890403879840079255169295922593080322634775209689623239873322471161642996440906533187938298969649928516003704476137795166849228875
```

### 3.4 Exponentiation
Let us implement a tail-recursive function that calculates the result of a given number (*base*) raised to the power of another number (*exponent*). The function should take two integer inputs, base and exponent, and return the result as a single integer.

We'll take a similar approach to our previous implementations:
1. Import the `tailrec` annotation.
2. Define two functions:
	- The first outer function will accept two `Int` type variables, `base` and `exp`.
	- The second nested function will accept our two `Int` type variables, `base` and `exp`, and a counter with `BigInt` type.
3. Call our outer function with two integer values.

We first import the `tailrec` annotation, and define our outer and nested recursive functions:

##### **Code**
```Scala
def ExpCalc(base: Int, exp: Int) : BigInt = {
    @tailrec
    def ExpItems(base: Int, exp: Int, counter: BigInt): BigInt = {
        if (base == 0) 0
        else if (exp == 0) 1
        else if (exp == 1) counter
        else ExpItems(base, exp - 1, base*counter)
    }
    ExpItems(base, exp, base)
}
```

We will then call our function with smaller and bigger numbers:

##### **Code**
```Scala
// Edge case call
ExpCalc(0, 0)

// Small integer call
ExpCalc(2, 2)

// Extense call
ExpCalc(8, 4)

// Even bigger call
ExpCalc(14328, 5)
```

##### **Output**
```
// res1: BigInt = 0

// res2: BigInt = 4

// res3: BigInt = 4096

// res4: BigInt = 603848322560489914368
```

## 4. Recommendations & best practices
As we saw from our previous examples, there are some common patterns when using recursion:
- We properly define our edge or boundary case(s). This case will be our stopper, and must be thought of carefully. Else, the implementation might enter an infinite loop and/or result in a memory error.
- We recursively call our function using some kind of modified parameter.

More particularly, with tail-recursion most of the times we will need to define a helper function that will provide some sort of counter or accumulator. This is because, in order to avoid any operation at the end besides the recursive call, we recursively call our function with modified arguments by using a counter to keep track. Else, we would effectively loose important tracking parameters in favor of our accumulator.

Of course, as we also saw, tail recursion is not infallible. Below are some recommendations to follow in order to ensure proper execution:
- **Ensuring tail-call optimization:** For this approach to work, we must place the recursive call as the last operation in the function, so the compiler can optimize it into a loop, avoiding stack overflow issues. We must particularly ensure that no further operations depend on the result of the recursive call.
- **Using accumulator variables:** We already mentioned counter or accumulator variables. They are used to carry the intermediate results through the recursion, reducing the need for additional computation or memory overhead. We can pass these variables as parameters in our recursive implementation.
- **Keeping it simple:** Tail-recursive functions should be designed with simplicity in mind; overcomplicating them defeats the purpose of elegance and clarity. We must avoid complex logic or nested conditional statements, as they can make the code harder to understand and maintain.
- **Using helper functions:** We already discussed this point. Using helper functions, also known as inner functions, to hide implementation details and encapsulate the tail-recursive logic can make the code more readable and maintainable. It also makes it possible to implement many tail-recursive functions in the first place.
- **Documenting our code:** Clearly document our tail-recursive functions, including a description of the function, input parameters, return values, and any edge cases. This will make it easier for others (*and ourselves*) to understand and maintain the code.
- **Testing edge cases:** This is a big one. We must thoroughly test our tail-recursive functions with a variety of input values, including edge cases such as negative numbers, zero, and large numbers. This will help ensure the correctness and stability of our implementation.
- **Considering alternatives:** While tail recursion is an effective technique for certain problems, it may not always be the best approach. We must consider alternative algorithms or data structures that might offer better performance or simplicity in some cases.
- **Understanding language/compiler limitations:** Some programming languages or compilers may not support tail-call optimization. Be aware of the limitations of the language or compiler we're are using, and consider alternative approaches if tail-call optimization is not supported or guaranteed.

## 5. Use cases
Apart from the mathematical applications we already reviewed, this technique can be used in a variety of real-life situations:
- **Tree traversal:** In data structures like trees or graphs, tail recursion can be used to traverse the structure in depth-first or breadth-first order efficiently. This can be particularly useful in scenarios like searching, sorting, or parsing XML/JSON files.
- **Parsing and tokenization:** Tail recursion can be utilized in compiler design, particularly in parsing and tokenization processes. When converting a source code file into tokens or parsing an expression, tail recursion can optimize memory usage and improve performance.
- **String manipulation:** In text processing, tail recursion can be employed for string manipulation tasks like string reversal, pattern matching, or substring search, providing an efficient and resource-friendly solution.
- **File and directory operations:** Tail recursion can be applied in file system operations such as directory traversal, file search, or file copying, to optimize memory consumption and improve performance.
- **Optimization problems:** Tail recursion can be applied in dynamic programming or other optimization problems, where a problem is broken down into smaller subproblems and solved iteratively. This can lead to efficient solutions that avoid redundant calculations and save memory.

Additionally, tail-recursion lets us think of problem solving in a different way.

---

# Higher-order functions
**Higher-order functions** are often attributed to the mathematician and computer scientist [Alonzo Church](), who developed the lambda calculus in the 1930s. 

## 1. Definition
Higher-order functions are one of the pinnacles of functional programming. They are very simple, yet extremely elegant and, well, functional. A higher-order function is one that accepts and/or returns a function instead of a value. In other words, a higher-order function is one that operates on functions.

This concept is easy to implement in Scala, since all functions are first-class citizens of the value type (*first-class values*), meaning they can be treated as values and be passed as arguments to other functions, returned as values from functions, and assigned to variables.

The basic syntax of a higher-order function is as follows:

##### **Code**
```Scala
// Higher-order function
def myfun(f: Int => Boolean, n: Int): Boolean = {
    f(n)
}

// Parameter function
def f(n: Int): Boolean = {
    n >= 1
}

// Higher-order function call
myfun(f, 1)
```

1. We first define our higher-order function that will accept a function `f`.
2. We then define a function f that accepts an `Int` value, and returns a `Boolean` value.
3. Lastly, we call our higher-order function with `f` as argument.

## 2. Advantages
Higher-order functions are basically an extra layer of abstraction done in a functional style. They are extremely useful when working with repetitive tasks, and can be used in conjunction with tail-recursive methods, providing an elegant and minimalist way to handle complex operations.

They are also extremely useful when flexibility and conciseness are required. Additionally, higher-order functions can help separate concerns by allowing us to separate the logic of a function from its implementation details.

As with any level of abstraction, this concept is tricky to grasp as first. Let us try to perform some simple examples in order to further clarify.

## 3. Examples
We'll review two examples of higher-order function implementations: The first one will be a simple case, while the second one will be more elaborate.

### 3.1 Single verification of a list
Let us implement a function that accepts a list of integers and a predicate function (`Int => Boolean`). The function should return the number of occurrences that satisfy the given predicate. The predicate function evaluates to `true` if the number is even.

We can follow the steps below:
1. Define an outer function that will accept a checker function, and our list containing the target numbers.
2. Define an inner function that will recursively go over all the numbers in the list, and pass then as arguments to our predicate function.
3. Define a predicate function that will evaluate if a given number is even.
4. Return the total number of occurrences by using a counter.

##### **Code**
```Scala
def checkList(checkerEven: Int => Boolean, list: List[Int]): Int = {
    def countElements(checkerEven: Int => Boolean, list: List[Int], counter: Int): Int = {
        if (list.isEmpty) counter
        else {
            if (checkerEven(list.head)) countElements(checkerEven, list.tail, counter + 1)
            else countElements(checkerEven, list.tail, counter)
        }
    }
    countElements(checkerEven, list, 0)
}

def checkerEven(target: Int): Boolean = {
    target % 2 == 0
}
```

If we call our higher-order function, we should get the following:

##### **Code**
```Scala
checkList(checkerEven, List(1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
```

##### **Output**
```
// : Int = 5
```

### 3.2 Variation of a summation
Let us define a function that accepts two integers, $a$, $b$, as upper and lower bounds, an integer $x$ for performing addition and product operations, and two functions as arguments. The function calculates a variation of the summation operation, where the first argument function will perform the addition operation for each term of the summation between $a$ and $b$, while the second one will calculate the product of the result of the previous operation with the parameter $x$.

Similar to the previous example, we can follow the steps bellow:
1. Define the higher-order function that will recursively call all the elements of the list.
2. Define a second function that will perform the addition operation.
3. Define a third function that perform the product operation.
4. Return the resulting value.

##### **Code**
```Scala
def sumNumbers(applyProduct: (Int, Int) => Int, applyAddition: (Int, Int) => Int, a: Int, b: Int, x: Int): Int = {
    if (a > b) 0
    else applyProduct(applyAddition(a, x), x) + sumNumbers(applyProduct, applyAddition, a + 1, b, x)
}

def applyProduct(n: Int, x: Int): Int = {
    n * x
}

def applyAddition(n: Int, x: Int): Int = {
    n + x
}
```

Let us explain the process step-by-step:
1. We define our three functions: `sumNumbers`, `applyProduct`, and `applyAddition`.
2. `applyProduct` takes two `Int` arguments, `n` and `x`, and returns their product (`n * x`).
3. `applyAddition` takes two `Int` arguments, `n` and `x`, and returns their sum (`n + x`).
4. `sumNumbers` takes five arguments: two function arguments `applyProduct` and `applyAddition`, which both have the type signature `(Int, Int) => Int`, and three `Int` arguments `a`, `b`, and `x`.
5. In `sumNumbers`, we define a conditional expression:
	- If `a > b`, the function returns `0`.
	- Else, the function calculates `applyProduct(applyAddition(a, x), x)` and adds it to a recursive call of `sumNumbers` with the same function arguments and `a` incremented by `1`.

We can finally call our function:

##### **Code**
```Scala
sumNumbers(applyProduct, applyAddition, 2, 3, 2)
```

##### **Output**
```
// : Int = 18
```

## 4. Recommendations & best practices
This technique has many flavors, and can be performed using named as well as anonymous functions. As we can see, it can become confusing if we don't do things in a clear way. This is why there are some best practices we can follow:
1. **Using clear naming**: It's best that we always use descriptive names for higher-order functions and their arguments to improve code readability and maintainability.
2.  **Using type annotations**: We can also specify types for function arguments and return values to ensure type safety and make the code more understandable.
3.  **Keeping functions small and focused**: Each function should have a single responsibility. This makes it easier to understand, test, and reuse the functions.
4.  **Leveraging immutability**: As is tradition with functional programming, using immutable data structures and avoiding side effects in higher-order functions can reduce the risk of bugs and improve code predictability.
5.  **Using standard library functions**: We can also take advantage of built-in higher-order functions like `map`, `filter`, and `reduce` instead of implementing custom iterations. This leads to cleaner, more idiomatic code.

## 5. Use cases
1.  **Data transformation**: To transform data in a collection, we can take advantage of higher-order functions like `map` that apply a specific function to each element.
2.  **Filtering data**: When it comes to refining data, we can use higher-order functions such as `filter` to selectively include or exclude elements based on a given condition.
3.  **Data aggregation**: Combining elements in a collection into a single result becomes easier when we employ higher-order functions like `reduce` or `fold` for custom aggregations like sums or products.
4.  **Function composition**: By embracing higher-order functions, we can create new functions through the combination or chaining of existing ones, which enhances code reusability and modularity.
5.  **Event handling**: In event-driven programming, we can harness higher-order functions to define and manage event listeners, simplifying the process of attaching or detaching specific behaviors to events.

---

# Currying
**Currying** is a technique that was introduced in the 1930s by the mathematician and logician [Haskell Brooks Curry](), as part of his work in combinatory logic. The concept of currying was further developed in the 1950s and 1960s by other mathematicians and computer scientists, such as [Alonzo Church](https://en.wikipedia.org/wiki/Alonzo_Church) and [John McCarthy](https://en.wikipedia.org/wiki/John_McCarthy_(computer_scientist)). It was then popularized in functional programming languages such as Lisp and ML.

## 1. Definition
Currying is a concept closely related with higher-order functions, because it builds on them. Currying consists of breaking down a function that takes multiple arguments into a series of functions that take one argument each. The functions can then be called sequentially using parenthesis.

## 2. Advantages
There are multiple advantages when working with currying techniques:
1.  **Modularity:** The functions can be broken down into smaller, more manageable parts. This can make code easier to read, write, and maintain.
2.  **Flexibility:** Currying provides flexibility by allowing functions to be partially applied or composed with other functions. This enables developers to create new functions from existing ones in a modular and flexible way.
3.  **Code reuse:** Currying allows generic functions to be parameterized with specific functionality. This reduces code duplication and promotes code reuse.
4.  **Type safety:** Currying provides type safety by ensuring that functions only accept arguments of the correct type. This reduces the likelihood of runtime errors and makes code more robust.
5.  **Partial evaluation:** We can perform partial evaluation by allowing functions to be evaluated with some of their arguments, while others are left to be supplied later. This can improve performance by reducing the need for repeated computations.

## 3. Examples
We'll perform two examples, the first one including a curried function, and the second one including a curried call to two functions.

### 3.1 A curried addition function
Let us implement a curried function called `add` that takes two integer arguments, `x` and `y`, and returns their sum. The function should be defined using multiple parameter lists, where the first parameter list takes one integer argument `x`, and the second parameter list takes one integer argument `y`. The function should be flexible and modular, allowing it to be partially applied or composed with other functions.

The steps to follow are straightforward:
1. Implement a curried function.
2. Partially call the curried function.
3. Complete the curried function call in a new line.

##### **Code**
```Scala
/ Define a curried function
def sumNums(x: Int)(y: Int) = {
    x + y
}

// Partial call
val first_call = sumNums(7) _

// Complete call
val second_call = first_call(3)
```

##### **Output**
```
// : Int => Int = <function1>
// : Int = 10
```

We use the `_` placeholder to indicate that we want to partially apply a function with one or more arguments. The `_` placeholder is used in place of the argument that we want to partially apply, and it indicates that we're creating a new function that takes the remaining arguments.

The type of `first_call` is actually a function we can apply to a given value. If we hover over `first_call` below the `Complete call` line, it will actually tell us the following:

##### **Output**
```
def apply(v1: Int): Int
Apply the body of this function to the argument.
**Returns:** the result of function application.
```

This is interesting, because we can apply `first_call` to any other value, and even a function. 

### 3.2 A curried call using two functions
Let us define a curried function that computes the sum of two values, $x$ and $y$, and then squares this result.

This one is a little bit trickier, since we need to first define a function that accepts the following:
- A function that will square the result.
- Two integers, $x$ and $y$, that will be operated on.
- A squaring function that will square the result.

Let us begin with the first one:

##### **Code**
```Scala
def sumInts(squareInt: Int => Int)(x: Int, y: Int): Int = {
    squareInt(x + y)
}
```

We can already see that the syntax is slightly different. What we're doing is:
- Define a curried function `sumInts` that has two parameter groups.
	- The first group is actually a function `squareInt` which accepts an integer and returns an integer.
	- The second group is our $x$, $y$ pair.
	- The function returns an integer type.
- Call the `squareInt` function on the sum of the $x$, $y$ value pair.

We then define our `squareInt` function:

##### **Code**
```Scala
def squareInt(a: Int): Int = {
    a*a
}
```

We can finally call our functions:

##### **Code**
```Scala
sumInts(squareInt)(2, 3)
```

This syntax is also slightly unconventional. Let us explain it:
- We first call our `sumInts` function with the first group of parameters *(i.e., the `squareInt` function)*.
- We then call our new composed function with the numbers we wish to operate on.

If we recall anonymous functions, each function inside our call, is an anonymous function, meaning it has no name.

We get the following output in return:

##### **Output**
```
// : Int = 25
```

As with the previous example, we could've also performed a partial call, and then use our new function as required:

##### **Code**
```Scala
val applySumSquare = sumInts(squareInt) _
```

##### **Code**
```Scala
applySumSquare(2, 3)
```

##### **Output**
```
// : Int = 25
```

## 4. Recommendations & best practices
1.  **Identifying suitable use cases**: We must consider using currying when partial application, function specialization, or improved type inference would benefit our code. 
2.  **Ordering parameters thoughtfully**: We can arrange parameters so that the ones most likely to be reused or pre-filled are in the initial parameter groups, making it easier to create partially applied functions.
3.  **Avoiding overusing currying**: We must be cautious not to overuse currying, as it can make the code harder to read and understand when used inappropriately.
4.  **Combining with other functional techniques**: We can enhance our code by combining currying with other functional programming techniques, such as function composition and higher-order functions.
5.  **Keeping function signatures clear**: When using currying, we must ensure that the function signatures remain clear and understandable, by providing appropriate type annotations and using descriptive parameter names.

## 5. Use cases
1.  **Reusable validators**: We can use currying to create reusable validation functions for user inputs in web applications, by partially applying common validation rules while leaving the input value to be applied later.
2.  **Customized event handlers**: In event-driven programming, we can use currying to create customized event handlers that have some pre-filled arguments, such as the event type or specific settings, allowing for flexibility and code reuse.
3.  **Configurable logging**: We can leverage currying to build configurable logging functions where the log level, message format, or output destination can be partially applied, making it easy to create specialized loggers with minimal code changes.
4.  **Flexible arithmetic operations**: In mathematical computations, we can utilize currying to create flexible arithmetic operations, such as specialized adders or multipliers, by partially applying one operand and allowing the other to be applied later.
5.  **Tailored data transformations**: In data processing pipelines, we can harness currying to generate tailored data transformation functions with specific rules or configurations partially applied, streamlining the process of applying these transformations to various data sets.

---

# Monads
**Monads** are a concept in functional programming originally developed in the 1960s in category theory, a branch of mathematics that studies abstract structures and relationships between them.

The concept in the context of functional programming was rediscovered by the computer scientist [Eugenio Moggi](), who published a paper in 1989 called "*[Computational Lambda Calculus and Monads](https://www.cs.cmu.edu/~crary/819-f09/Moggi89.pdf)*". Monads were first introduced in Haskell in the early 1990s, and still comprise a core part of the language.

## 1. Definition
A monad, is the English translation for *"monada"* in Spanish, which interestingly enough, means cute little thing (*that is, if we eat the accent since my keyboard has US layout and [Keychron](https://www.keychron.com/) is to blame*) (*And no, its not a referral link, I really love my keyboard, which I'm sure cannot be said for my family hearing the thick thock at 6 am*).

Jokes aside, a monad is a design pattern used to encapsulate and manipulate computations that produce values of a specific type, abstracting away the details of the computation. 

In simpler terms, a monad can be thought of as a "*container*" or a "*wrapper*" that holds a value and provides a standardized way to perform operations on that value. Monads are of huge help when chaining computations and handling side effects, making it easier to reason about and structure code.

Monads exist in various languages *(mainly in functional ones)*, such as Haskell, Scala, F#, Swift, JavaScript, Kotlin, [Rust](https://pabloagn.com/blog/rust-for-beginners/), and even Python. While some languages have built-in support for monads, many others can utilize monadic concepts through third-party libraries or by implementing monad patterns manually.

## 2. Advantages
Monads were introduced to computational theory as a way to handle side-effects; if we have a chain of operations represented by functions, that will eventually result in a return value, monads make sure that, if a given step produces an unintended value (*such as `null` or `nil` values*), there will be an appropriate handling for that, thus avoiding an error return.

More specific, in functional programming we usually want to define our chains of operations using functions. If we would like to execute a given chain of functions without errors, we could define an intermediate function that handles the types behind the scenes *(sort of a checker)*, so that when we call our chained functions and the first function returns an "*unexpected*" value, we can handle that within our chain. More importantly, we're abstracting this concept into a function that can be reused in as many intermediate steps as we would like. This could potentially save us a lot of time of exception writing.

Another great example in functional programming is the purity of functions. A function is pure if it returns the same value over and over again. An impure function might return different values when calling with the same input. We can employ monads to ensure that impure functions return a boxed value *(i.e., a value of a primitive type that has been wrapped or "boxed" into an object of a corresponding reference type)*.

So why go all about this fuzz, when we can simply build an exception handling with conditionals or assertions? Well, there are some advantages to monads that the previous simply cannot offer:
- **Explicit error handling:** Monads like `Option`, `Either`, and `Try` make error handling more explicit, as they encode the possibility of failure directly in the type system.
- **Improved code readability:** They can also make code more readable and maintainable by abstracting away error handling boilerplate. Chaining monadic operations using `flatMap`, `map`, and `for` comprehensions can lead to cleaner and more concise code compared to nested conditionals or `try`-`catch` blocks.
- **Encapsulation of side effects:** Monads can be used to encapsulate side effects, making it easier to reason about the code. This is particularly useful in functional programming, where immutability and the absence of side effects are desired properties. Monads like `IO` in Haskell or `Task` in Scala help manage side effects in a controlled manner, without breaking the functional programming principles.
- **Composability:** Monads are highly composable, allowing us to chain multiple operations together in a clean and concise way. This can lead to more modular and reusable code compared to using conditionals and assertions. Additionally, monads can be used with higher-order functions and other functional programming techniques.
- **Avoiding exceptions:** Exceptions can be expensive in terms of performance, and they can make it more difficult to reason about the control flow of our program. By using monads, we can return a value representing success or failure, and handle errors in a more controlled and predictable manner.

Monads are confusing if explained with simple words. This is why we'll spend appropriate time exploring one of them with a simple example.

## 3. Examples
Let us explore one case, where we have a chain of two functions, and would like to ensure proper and smooth execution between them:

### 3.1 An undefined operation
We would like to pack two expressions into two separate functions, and perform them consecutively: 
- Value A divided y Value B equals Value C
- Value C divided by Value D equals E

##### **Code**
```Scala
// Unsafe division one
def unsafeDivOne(UnsafeDivTwo: (Double, Double)  => Double, a: Double, b: Double, d: Double): Double = {
    UnsafeDivTwo(a, b) / d
}

// Unsafe division two
def UnsafeDivTwo(a: Double, b: Double): Double = {
    a / b
}
```

If we call our first function with positive real numbers, we'll get the expected result:

##### **Code**
```Scala
unsafeDivOne(UnsafeDivTwo, 12, 2, 3)
```

##### **Output**
```
// res1: Double = 2.0
```

However, as simple as this example is, it can easily fail; if we feed 0 to the parameter B, the result of the expression becomes undefined, and the execution returns infinity.

##### **Code**
```Scala
unsafeDivOne(UnsafeDivTwo, 12, 0, 3)
```

##### **Output**
```
// res1: Double = Infinity
```

Let us redefine our unsafe implementations to safe ones:

##### **Code**
```Scala
// Safe division one
def safeDivOne(SafeDivTwo: (Double, Double) => Option[Double], a: Double, b: Double, d: Double): Option[Double] = {
    if (b != 0 & d != 0) {
        safeDivTwo(a, b).flatMap(result => safeDivTwo(result, d))
    }
    else None
}

// Safe division two
def safeDivTwo(a: Double, b: Double): Option[Double] = {
    if (b != 0) Some(a / b)
    else None
}
```

In this solution, we use the `Option` monad to handle the possibility of a division by zero. `Option` is a container type that represents the presence or absence of a value. It has two subclasses: `Some` and `None`.

`Some` represents a value being present, whereas `None` represents the absence of a value. By using `Option` and the `flatMap` function, we can chain operations and handle the absence of a value elegantly and effectively.

This can be a little confusing, so lets explain what we're doing step-by-step:
1. Define the `safeDivOne` function:
	- It takes a function `safeDivTwo` as a parameter, which has the type `(Double, Double) => Option[Double]`.
	- It also takes three `Double` parameters: `a`, `b`, and `d`.
2. Check if both `b` and `d` are non-zero:
	- If either `b` or `d` is zero, the function returns `None` as the result, indicating that the division cannot be performed.
	- In this case, `None` is used to represent the absence of a valid division result.
3. If both `b` and `d` are non-zero, perform the first division operation:
	- Call the `safeDivTwo` function with `a` and `b` as arguments.
	- This will return an `Option[Double]` representing the result of the first division operation.
	- If the division is valid, the result is wrapped in a `Some`, indicating the presence of a value. Otherwise, it returns `None`.
4. Chain the second division operation using the `flatMap` method:
	- The `flatMap` method is used on the `Option[Double]` returned by the first division operation. It helps in chaining the operations when working with monads like `Option`.
	 - It takes a function as its argument, which receives the inner value of the `Option[Double]` (the result of the first division operation) only if it's a `Some`.
	- The function calls `safeDivTwo` with the result of the first division and `d` as arguments.
	- This will return an `Option[Double]` representing the result of the second division operation, again wrapping the result in a `Some` if the division is valid, or returning `None` otherwise.
5. Return the final result, which is an `Option[Double]` representing the result of both division operations or the absence of a valid result.
6. Define the `safeDivTwo` function:
	- It takes two `Double` parameters: `a` and `b`.
	- It checks if `b` is non-zero.
	- If `b` is non-zero, it returns `Some(a / b)` as the division result, wrapping the value in a `Some` to indicate the presence of a valid result.
	- If `b` is zero, it returns `None` to indicate that the division cannot be performed, representing the absence of a valid result.
7. Call the `safeDivOne` function with the `safeDivTwo` function, `12`, `2`, and `3` as arguments, and store the result in a variable.

We can then call our function with unsafe parameters:

##### **Code**
```Scala
safeDivOne(safeDivTwo, 12, 0, 3)
```

And the output will be what we intended.

##### **Output**
```
// res1: Option[Double] = None
```

Of course, there's no point in making all this effort if the user gets a `None` value as a result.

This is where our next technique, pattern matching, comes into play.


## 4. Recommendations & best practices


## 5. Use cases


---

# Pattern matching and extractors
The concept of **pattern matching** has been used in various forms in different programming languages and systems, but its specific use in functional programming is often attributed to the computer scientist [David Turner](https://en.wikipedia.org/wiki/David_Turner_(computer_scientist)).

Turner also invented the functional programming language [Miranda](https://en.wikipedia.org/wiki/Miranda_(programming_language)), which was one of the first languages to incorporate pattern matching as a core feature. It was introduced in the 1980s and used a syntax for pattern matching that has since become a common feature in many functional programming languages, including [Haskell](), [F#](), and [Scala]().

The concept of **extractors** is also often attributed to David Turner, who introduced them as a feature of the same language.

## 1. Definition
Pattern matching is a powerful technique, where we can.

## 2. Advantages

## 3. Examples
If we recall from our last technique, we were using the `Option` monad to implement two safe division functions that can deal with undefined values *(i.e., division by zero)*.

In our first example, we'll add some more functionalities to this implementation.

### 3.1 Handling an undefined operation
We can extend our `safeDivision` functionality by using pattern matching:

##### **Code**
```Scala
def checkDivide(result: Option[Double]) = {
    result match {
    case Some(value) => println(s"Division result: $value")
    case None        => println("Division by zero is not allowed")
    }
}
```

Now, we simply feed our expression:

##### **Code**
```Scala
checkDivide(safeDivOne(safeDivTwo, 12, 2, 3))
checkDivide(safeDivOne(safeDivTwo, 12, 0, 3))
```

##### **Output**
```
// Division result: 2.0
// Division by zero is not allowed
```

### 3.2 Matching an animal species
Let us create a simple application that takes an input string representing an animal's name and, using pattern matching, determines the animal's classification within a basic hierarchy. The hierarchy consists of 3 levels: Mammal, Bird, and Reptile. We need to match the input animal to the correct classification and return the correct class as a `String`.

##### **Code**
```Scala
// Define an animal checker
def checkAnimal(animal: String): String = {
    animal match {
        case ("Elephant" | "Whale" | "Dog") => "Mamal"
        case ("Parrot" | "Eagle" | "Penguin") => "Bird"
        case ("Lizard" | "Tortoise" | "Snake") => "Reptile"
        case _ => "Animal is not in DB, sorry."
    }
}

// Define an animal
val my_animal = "Snake"

// Call function
checkAnimal(my_animal)
```

##### **Output**
```
res1: String = "Reptile"
```

### 3.3 Matching a data type
Let us define a function that checks for 4 basic base data types in Scala. The function accepts a value `x`, and returns the corresponding type as `String`.

For this example, we'll actually define two versions of the same function: one using pattern matching, and the other using if-else if-else constructs.

##### **Code**
```Scala
// Implement using pattern matching
def checkType1(x: Any): String = x match {
  case _: Int => "Int"
  case _: String => "String"
  case _: Boolean => "Boolean"
  case _ => "Unknown"
}

// Implement using a if-else constructs
def checkType2(x: Any): String = {
  if (x.isInstanceOf[Int]) "Int"
  else if (x.isInstanceOf[String]) "String"
  else if (x.isInstanceOf[Boolean]) "Boolean"
  else "Unknown"
}

// Call functions
checkType1(1)
checkType2(1)

checkType1("A String")
checkType2("A String")
```

While both implementations return the same value, the first function is much more concise and readable since we're using a placeholder `_`, while the second one requires additional methods in order to do the same.

##### **Output**
```
res1: String = "Int"
res2: String = "Int"

res3: String = "String"
res4: String = "String"
```

### 3.4 Extractors with a custom class
Let us define a custom class called `PositiveInt`, which can represent a positive integer object. We want to be able to check if an integer is positive by using the `PositiveInt` constructor and pattern matching.

##### **Code**
```Scala
// Define our custom class
class PositiveInt(val value: Int)

// Define an object
object PositiveInt {
  def unapply(value: Int): Option[PositiveInt] =
    if (value > 0) Some(new PositiveInt(value)) else None
}

// Define a checker that includes an extractor
def checkNum(x: Int) = x match {
  case PositiveInt(positiveInt) => println(s"The number ${positiveInt.value} is positive.")
  case _ => println(s"The number ${x} is not positive.")
}

checkNum(7)
checkNum(-10)
```

##### Output
```
// The number 7 is positive.
// The number -10 is not positive.
```

Let us explain our algorithm more in detail:
1. We declare a class `PositiveInt`, which accepts an integer value.
2. We declare a companion object `PositiveInt`, which will contain (*encapsulate*) the extractor method using `unapply`. What this will do is destructure an object belonging to the `PositiveInt` class, and extract its value. If our object is not a positive integer, it will return `None`, and the pattern-matching implementation will catch it.
3. We define a pattern matching implementation that calls the `PositiveInt` class with a variable `positiveInt`, that will hold the deconstructed `PositiveInt` value if its positive.

## 4. Recommendations & best practices
1. **Avoiding missing cases:** We must cover all possible cases in our pattern matching expressions. Scala's compiler checks for exhaustiveness, and by adding a wildcard pattern (`case _ =>`) as a catch-all, we can handle any unexpected cases.
2. **Eliminating type checks and type casts:** We can use pattern matching to destructure and match on types instead of relying on `isInstanceOf` and `asInstanceOf`. This approach leads to cleaner and safer code.
3. **Embracing sealed traits and case classes:** We should prefer sealed traits and case classes when working with algebraic data types. Sealed traits enable the compiler to perform exhaustiveness checks, while case classes provide built-in support for pattern matching, immutability, and useful methods like `copy` and `equals`.
4. **Implementing extractor objects and unapply methods:** We can create custom data structures or classes with extractor objects and `unapply` (or `unapplySeq` for sequences) methods to facilitate pattern matching. This allows us to destructure and extract values from our custom data structures just like with case classes. 
5. **Prioritizing simplicity and maintainability:** We should organize our pattern matching expressions for readability and avoid overly complex patterns that can be difficult to understand.

## 5. Use cases
At this point, it would be valid if we ask ourselves: well, why use `match` if we already have an `if-else if-else` construct?

Well, we saw a very simple example, but logical tests can increase in size and include complex patterns that we must match. In this case, a pattern-matching approach simply provides better readability. Also, logical tests can include complex data structures such as multidimensional arrays; pattern matching is optimized to handle those. 

Additionally, as we already saw, pattern matching supports a simplified syntactic construct for type checking; this is extremely useful if we're working with custom types, or even the base ones.

So, some rules would include the following:
- If we have a simple logical test we'd like to perform, we use an `if-else` construct.
- If we have a more complex set of logical rules, we use pattern matching.
- If we wish to perform type checking, we use pattern matching.

What about extractors? As we might suspect, most applications involve some type of value extraction from a given class to check something, or operate with something else:
1. **Parsing strings:** We can extract specific components from formatted strings, such as email addresses, URLs, or date formats.
2. **Destructuring custom data structures:** We can also simplify access to nested values or elements in complex data types.
3. **Type-based pattern matching:** We can match and extract values based on their types, eliminating the need for explicit type checking and casting.
4. **Matching expressions with additional conditions:** As we saw in our last example, we can apply custom logic or constraints during pattern matching, making match expressions more expressive.
5. **Simplifying complex pattern matching:** We can create more readable and maintainable pattern matching expressions by encapsulating custom matching logic in extractors.

---

# Lazy evaluation
The concept of **lazy evaluation** has been around for a long time and has been used in various forms in different programming languages and systems. However, the term "*lazy evaluation*" was coined in the 1970s by the computer scientist [Peter J. Landin](https://en.wikipedia.org/wiki/Peter_Landin) in his paper *"[The Next 700 Programming Languages](https://www.cs.cmu.edu/~crary/819-f09/Landin66.pdf)"*.

It was also highly influenced by Daniel Friedman and David Wise in their paper *"[Cons should not evaluate its arguments](https://help.luddy.indiana.edu/techreports/TRNNN.cgi?trnum=TR44)"*.

## 1. Definition
Lazy evaluation is an extremely important concept, specifically (*but not exclusively*) in the context of big data processing pipelines. Lazy evaluation or call-by-need is an evaluation strategy where an expression isn’t evaluated until its first use (*i.e, to postpone the evaluation till its demanded*).

## 2. Advantages


## 3. Examples
If we've been following this article from the start, we might have noticed that all the functions we implemented are eagerly evaluated every time they're called. This means the function is executed and its result is computed each time we invoke it.

We can however, declare a lazy function or value by using the `lazy` keyword:

### 3.1 Defining a simple lazy value
Let us declare two simple variables: An eager variable and a lazy one:

##### **Code**
```Scala
// Define an eager list and a lazy list
val my_list:List[Int] = List(1, 2, 3, 4, 5)
lazy val my_lazy_list:List[Int] = List(1, 2, 3, 4, 5)
```

If we hover over the variable name, we will see that the eager variable already returns its value, while the second does not:

##### **Output**
```
my_list: List[Int] = List(1, 2, 3, 4, 5)
lazy private val my_lazy_list: List[Int]
```

While we can define lazy values, the same does not apply for functions; functions are eagerly evaluated by default and can't be made lazy like `val`s can using the `lazy` keyword.

However, we can achieve lazy evaluation of function results by returning a `lazy val` or by using [memoization](https://medium.com/musings-on-functional-programming/scala-optimizing-expensive-functions-with-memoization-c05b781ae826) techniques to cache the function results.

## 4. Recommendations & best practices
1. **Using `lazy` only when necessary:** While `lazy` values can be useful for reducing computational overhead, they can also introduce additional complexity and potential for bugs. We should use `lazy` only when we have a good reason to defer evaluation and keep in mind that laziness may introduce unexpected behavior, such as initialization order issues.
2. **Avoiding side effects:** We should avoid using `lazy` values that have side effects, as their evaluation is not guaranteed to happen exactly once. Side effects can also introduce unexpected behavior, such as race conditions and thread-safety issues.    
3. **Memoizing expensive computations:** We should use memoization techniques to cache the results of expensive computations in `lazy` values. This can improve performance by avoiding recomputing the same result multiple times.
4. **Keeping the scope small:** We should limit the scope of `lazy` values to where they're needed, as they may introduce additional memory overhead. We should avoid defining `lazy` values at the top-level or in long-lived objects, as their memory may be retained for longer than necessary. 
5. **Being mindful of serialization:** We should keep in mind that `lazy` values may not serialize properly and may need to be manually re-initialized after deserialization. If we need to serialize objects that contain `lazy` values, we should ensure that they are properly initialized before serialization.

## 5. Use cases
As we might suspect, lazy evaluation is useful when we want to optimize the performance and memory usage of a given application. Again, this is specially important when working with big data. However, that's far from being the only potential application:
1. **Initialization-on-demand:** We can use `lazy` values to defer initialization until they are needed. This can help reduce overhead and improve performance.
2. **Memoization:** We can also use `lazy` values to cache expensive computations and avoid recomputing the same result multiple times.    
3. **Thread-safe lazy initialization:** We can use `lazy` values to implement thread-safe initialization of objects or resources.
4. **Lazy loading:** We can use `lazy` values to lazily load resources such as configuration files, data sets, or images. 
5. **Circular dependencies:** We might want to use `lazy` values to break circular dependencies between objects or classes. This can help avoid initialization order issues and improve modularity.


---

# Implicits and type classes
**Implicits** and **type classes** are two different but closely-related concepts widely used in functional programming languages, particularly in Scala. While the development of these concepts was a collaborative effort among many programmers and researchers, the contributions of [Martin Odersky](https://en.wikipedia.org/wiki/Martin_Odersky), the creator of Scala, were particularly significant.

## 1. Definition
**Implicits** are a way of implicitly passing values, objects, or functions as arguments to a method or function call

The implicit system in Scala allows the compiler to adjust code using a well-defined lookup mechanism. We can leave out information that the compiler will attempt to infer at compile time. The Scala compiler can infer one of two situations:
- When a method call or constructor with a missing parameter.
- When we have missing conversion from one type to another type. This also applies to method calls on an object that would require a conversion.

In both of these situations, the compiler follows a set of rules to resolve missing data and allow the code to compile. When we leave out parameters, it’s incredibly useful and is done in advanced Scala libraries. The compiler converting types to ensure that an expression compiles can be more dangerous.

**Type classes**, on the other hand, are a way of defining a set of operations or behaviors that can be applied to a type or class, without modifying the type or class itself. In simpler terms, type classes enable us to make a function more ad-hoc polymorphic without touching its code.

If we've already used type classes in Python (*by employing the `@` annotation*), then we are already familiar with this concept.

In Scala, things are similar.

## 2. Advantages
Regarding implicits, there are many advantages if used properly:
1. **Extension methods:** We can define extension methods for existing classes or types, without modifying the original source code.
2. **Type-safe DSLs:** We can use implicits to create type-safe DSLs that are both expressive and easy to use.
3. **Implicit conversions:** We can define implicit conversions to automatically convert between types, making our code more concise and readable.
4. **Type inference:** We can use implicits to help the compiler infer types, reducing the amount of boilerplate code we need to write.
5. **Flexible API design:** We can use implicits to create flexible APIs that can be easily customized and extended by users, without modifying the underlying source code.

Regarding **type classes**, the main advantages go around designing polymorphic functions that can inherit a full set of traits from another class. This of course, provides a valuable tool for promoting code modularization and reusability. 

## 3. Examples
Working with implicits requires a a lot of practice, and specially, expertise in type definition and type behavior, since they're one of the features that, if misused, can drastically reduce the quality of our code by introducing bugs and increasing build and execution times. However, there are plenty of use cases we can explore.

Type classes also require a fair amount of practice; if we're not careful, we can end up with a code that's virtually unintelligible and impossible to decipher. Also, we can introduce unwanted side-effects, a characteristic that functional programming tries to avoid at all costs.

Let us define a very simple example.

### 3.1 Finding an integer
Let us declare a function that accepts an integer value, and returns the same value. We'll define its parameter as implicit, and study its behavior.

##### **Code**
```Scala
// Define a function with implicit parameter x
def findInt(implicit x: Int) = x

// Call function without argument
findInt
```

As expected, we get an error:

##### **Output**
```
could not find implicit value for parameter x: Int
```

This is because we have not yet declared an implicit value that falls under the scope of the implicit parameter lookup. Let us do that:

##### **Code**
```Scala
// Define a function with implicit parameter x
def findInt(implicit x: Int) = x

// Define an implicit value
implicit val my_int: Int = 10

// Call function without argument
findInt
```

##### **Output**
```
res1: Int = 10
```

Surprise surprise, the function gets magically evaluated. What happened was close to magic, but not quite magic; we defined a value `my_int` under the implicit scope. The set of rules for implicit values in the Scala compiler then looked for this value, and found one that matched the required type `Int`.

What if we declare another implicit `Int`?

##### **Code**
```Scala
// Define a function with implicit parameter x
def findInt(implicit x: Int) = x

// Define two implicit values
implicit val my_int: Int = 10
implicit val my_int_2: Int = 7

// Call function without argument
findInt
```

##### **Output**
```
ambiguous implicit values:  
both value my_int_2 in class MdocApp of type => Int  
and value my_int in class MdocApp of type => Int  
match expected type Int
```

We will get an ambiguous implicit value error: since both values belong to the same scope, the compiler does not know which value to evaluate the function with.

But what if in turn, we declare a value of a different type?

##### **Code**
```Scala
// Define a function with implicit parameter x
def findInt(implicit x: Int) = x

// Define an implicit value
implicit val my_int: Int = 10
implicit val my_string: String = "A String"

// Call function without argument
findInt
```

##### **Output**
```
res1: Int = 10
```

This works perfectly, because our second implicit value, `my_string`, is not of the required type, and the Scala compiler knows that.

### 3.2 Value formatter
Let us define a type class that can format different types when printing them to `stdout`. We want to be able to use two types: `String` and `Int`.

##### **Code**
```Scala
trait Formatter[T] {
  def format(value: T): String
}

// Define a Formatter object, including two
// implicit objects: String and Int
object Formatter {
  implicit object IntFormatter extends Formatter[Int] {
    def format(value: Int): String = s"The integer value is $value"
  }

  implicit object StringFormatter extends Formatter[String] {
    def format(value: String): String = s"The string value is $value"
  }
}

// Define the formatter method
def printFormatted[T](value: T)(implicit f: Formatter[T]): Unit = {
	println(f.format(value))
}

// Format an int and a string
printFormatted(777)(Formatter.IntFormatter)
printFormatted("a string")(Formatter.StringFormatter)
```

Let us explain more in detail what we just declared:
1. We define a type class using `trait`. Traits are like templates for classes in Scala. They define a set of methods and fields that can be mixed in to a class to provide additional functionality, without requiring the class to inherit from a specific superclass.
2. We define an object `Formatter`, that will encapsulate two implicit objects: `IntFormatter` and `StringFormatter`, one for each type.
3. We declare a method for each case:
	1. We mark both formatter objects as `implicit`, which means that they can be used to provide a default `Formatter` instance for `String` and `Int` values.
	2. We extend the functionality of `Formatter` with these two methods.
4. We then simply create a function that will print the formatted type.

##### **Output**
```
// The integer value is 777
// The string value is a string
```

We can look at it this way:
- **What do the two printing statement results have in common?**
- They accept a value and print it as string. This is what the `trait` does.
- **What is the main difference between `IntFormatter` and `StringFormatter`?**
- They format the string differently before printing it to `stdout`.

We can thus say that the `IntFormatter` and `StringFormatter` have effectively extended the functionality of `Formatter`, which provides a base template of the printing method for both types.

It would be of huge surprise to us that Scala has this incredible feature. The thing is that Scala combines the best of both worlds: Functional & OOP programming.

## 4. Recommendations & best practices
As with any powerful abstraction technique, there are some best practices we can use in order to avoid [Fauda](https://www.thesun.co.uk/tvandshowbiz/11354802/what-does-fauda-mean/).
1. **Making sure class type names are clear and concise:** We should choose names that accurately describe the purpose of the class and follow standard Scala naming conventions.
2. **Being able to define class type parameters in a way that makes the class more generic and reusable:** We can use type parameters to define generic behaviors and interfaces that can be used by different types.
3. **Encapsulating class state and behavior to maintain abstraction and modularity:** We can use private and protected modifiers to restrict access to internal class details and expose a public API for interaction with the class.
4. **Using case classes for immutable data structures:** Case classes are designed to provide a convenient and efficient way to define immutable data structures, and have built-in support for pattern matching and equality testing.
5. **Making sure class types are composable and interoperable:** We can use traits and mixins to define reusable behaviors that can be mixed in to different class types, and adhere to standard Scala conventions for interoperability with other libraries and frameworks.

## 5. Use cases
1. **Implementing data models for complex applications:** Class types are a natural way to represent complex data structures and relationships between entities in an application.
2. **Defining reusable behavior for different classes:** We can use traits and mixins to define reusable behaviors that can be shared among different class types, promoting code reuse and modularity.
3. **Creating custom collections and data structures:** We can use class types to define custom collections and data structures that meet the specific needs of our application, such as efficient lookup or specialized iteration behavior.
4. **Implementing stateful and event-driven applications:** Class types can be used to model stateful entities and represent events and actions that change the state of the application.
5. **Interacting with external systems and libraries:** We can use class types to define data structures and interfaces for interacting with external systems and libraries, promoting interoperability and encapsulation of external dependencies.

---

# Continuation-passing style (CPS)
The concept of **CPS** can be traced back to the work of several computer scientists, including [John McCarthy](https://en.wikipedia.org/wiki/John_McCarthy_(computer_scientist)), [Peter Landin](https://en.wikipedia.org/wiki/Peter_Landin), and [Christopher Strachey](https://en.wikipedia.org/wiki/Christopher_Strachey).

However, the specific term "*continuation-passing style*" and its use in programming languages can be attributed to the American computer scientist [Daniel P. Friedman](https://en.wikipedia.org/wiki/Daniel_P._Friedman) and his colleagues. In the early 1970s,

## 1. Definition
This one is tricky to define without any previous context of what continuation is. Because of this, we'll first define a few concepts that will be useful.

### 1.1 Continuation
A **continuation** is a primitive construct to abstract control flow. It represents a point in time of a given execution flow. A continuation usually consists of two states:
- The program state at a given point in time.
- The remaining code to run.

So, in simpler terms, if we're executing a program and we define a breaking point in a given line, we save a picture of the program at that particular point in time.

The remaining code to be run is also saved as part of the snapshot.

### 1.2 Continuation-passing style (CPS)
CPS is simply a way to implement continuations in a program. More formally, CPS is a way of writing programs that has proven useful as an intermediate form in compiling functional languages. By using CPS, things like order of evaluation and temporary variables are made explicit. We must remember that CPS is simply a programming style that can be adopted by mixing it with other styles; using one CPS implementation does not mean we require our entire code to work that way.

Thinking in terms of functional programming, we know that the main way to abstract a computation is by using functions and their variations. It would then make sense to define a CPS as a function that abstracts continuation.

If we don't yet know where we're going, that's OK. This concept is confusing. However, what we ultimately want, is to control the control flow.

Let us think of a more concrete example, where we would like to define two functions: The first one will add two integer values, and the second one will calculate the product of the result with another integer value we designate.

We'll start with the conventional style:

##### **Code**
```Scala
// Define an addition function
def addInts(x: Int, y: Int): Int = {
    x + y
}

// Define a multiplication function
def multiplyInts(d: Int, z: Int): Int = {
    d * z
}

// Declare test variables
val x1 = 7
val y1 = 14
val z1 = 21

// Call both functions
println(s"($x1 + $y1) * $z1 = ${multiplyInts(addInts(x1, y1), z1)}")
```

##### **Output**
```
// (7 + 14) * 21 = 441
```

Simple, right?

Now, let us define an equivalent implementation using CPS style:

##### **Code**
```Scala
// Define an addition function
def addIntsCPS(x: Int, y: Int, k: Int => Unit): Unit = {
    k(x + y)
}

// Define a multiplication function
def multiplyIntsCPS(d: Int, z: Int, k: Int => Unit): Unit = {
    k(d * z)
}

// Declare test variables
val x2 = 7
val y2 = 14
val z2 = 21

addIntsCPS(x2, y2, sum => {
  multiplyIntsCPS(sum, z2, product => {
    println(s"($x2 + $y2) * $z2 = $product")
  })
})
```

Let us explain step by step:
- We define an addition function `addIntsCPS`, which now takes one additional argument `k`. This additional argument is our continuation function.
- The `addIntsCPS` also accepts two integers, but does not return the value to the execution process. Instead, it returns it to another function (*i.e., the continuation function*).
- The exact same happens with `multiplyIntsCPS`.
- We then define values to use in our call.
- We call `addIntsCPS` with our `Int` arguments, but also include a call to the anonymous continuation function using `sum` as argument (*`k` accepts an `Int`, and returns a `Unit`*)
- The continuation function receives the `sum`, and then calls `multiplyCPS` with the `sum`, `z`, and another continuation function that takes the product as its argument.
- Inside the `multiplyCPS` function, `sum * z` is calculated, and the result is passed to the next continuation function.
- The last continuation function receives `product` and sends the result to `println`.

As expected, we get the same result:

##### **Output**
```
// (7 + 14) * 21 = 441
```

If we noticed, this mechanism provided us a way to control the flow of the process, but it also provided a funny syntax. This type of syntax is well known in a wide variety of languages, and is sometimes referred to as [callback hell](http://callbackhell.com/) in the context of JavaScript, but really applies to any language dealing with functions.

In short, CPS has many advantages, but its abuse can lead to poor syntax.

## 2. Advantages
If we are to implement such a concept, it must have some great advantages, right? Yes, CPS has plenty of use cases we can explore. We can mention some of them:
1. **Improving control flow:** CPS makes the control flow of our program explicit, making it easier to understand and manage, especially in asynchronous scenarios.
2. **Chaining operations:** CPS allows us to chain multiple operations by passing the continuation functions as arguments, improving code readability.
3. **Tail-call optimization:** CPS can enable tail-call optimization in languages that support it, which can help avoid stack overflow errors in deep recursion.
4. **Non-blocking code:** CPS is well-suited for non-blocking and asynchronous programming, as it avoids blocking calls and promotes efficient resource usage.
5. **Enhancing modularity:** By using continuation functions, CPS promotes modular code design, making it easier to extend, maintain, and debug our code.

## 3. Examples
Let us go over one additional example to further clarify the CPS style:

### 3.1 Algebraic calculations on lists of integers
Let us imagine a scenario where we have a list of integers and we want to calculate the sum and product of all elements in the list, but we want to use CPS to break the problem into smaller parts.

Let us start by defining what we'll need to achieve this:
- A `sumListCPS` function that will perform a sum operation on a list of integers, and will return the result to a continuation function `k`.
- A `productListCPS` function that will perform a product operation on a list of integers, and will return the result to a continuation function `k`.
- A list of `Int` values.
- A call to the CPS functions we defined previously.

##### **Code**
```Scala
def sumListCPS(list: List[Int], k: Int => Unit): Unit = k(list.sum)

def productListCPS(list: List[Int], k: Int => Unit): Unit = k(list.product)

val numbers = List(7, 14, 21, 28, 35)

sumListCPS(numbers, sum => {
  println(s"Sum: $sum")

  productListCPS(numbers, product => {
    println(s"Product: $product")
  })
})
```

##### **Output**
```
// Sum: 105
// Product: 2016840
```

## 4. Recommendations & best practices
As with many of the concepts we're reviewed in this segment, CPS is a technique that if used right, can bring a lot of advantages. On the contrary, if misused or abused, it can reduce our quality code and introduce unnecessary bugs. Below are some recommendations when dealing with CPS in functional programming:
1. **Using function composition:** We can compose CPS functions using higher-order functions to create reusable and modular code, improving readability and maintainability.
2. **Using tail-recursive CPS functions:** We should aim to write tail-recursive CPS functions when dealing with recursion, as it enables tail-call optimization and prevents stack overflow errors in languages that support it.
3. **Using meaningful continuation names:** We must choose descriptive names for continuation functions to improve code readability and make it easier to understand the purpose and flow of each continuation.
4. **Using type annotations:** We can improve code clarity and maintainability by adding type annotations to CPS functions and their continuation arguments, making it easier to understand the expected input and output types.
5. **Using CPS selectively:** We must evaluate whether using CPS is the best solution for a given problem, as CPS might not be the optimal choice for simple, non-asynchronous scenarios. In such cases, using conventional programming styles might be more suitable and result in more readable code.

## 5. Use cases
CPS, and continuation in particular, are vast subjects with many variations we can implement. However, we can mention some real-world use cases:
1. **For asynchronous programming:** We can manage complex asynchronous operations by chaining multiple callbacks, avoiding callback hell, and improving code readability.
2. **In compilers and interpreters:** We can leverage CPS for implementing language features like exception handling, garbage collection, and concurrency in compilers and interpreters.
3. **For state machines:** We can model state machines with CPS by representing different states as continuation functions, providing a clear and modular way to handle state transitions.
4. **For cooperative multitasking:** We can apply CPS to implement cooperative multitasking, where tasks voluntarily yield control by calling their respective continuation functions, improving resource usage and scheduling.
5. **For backtracking algorithms:** We can use CPS to implement backtracking algorithms, enabling efficient exploration of potential solutions and making it easier to revert to previous states when a solution is not found.

---

# Futures and Promises
**Futures** and **promises** are concepts that have been used in computer science and programming languages for many years. They are particularly popular in functional programming languages, where they are used for asynchronous and concurrent programming.

The concept of **futures** was first introduced in the 1970s by [Barbara Liskov](https://en.wikipedia.org/wiki/Barbara_Liskov) and [Alan Snyder](https://en.wikipedia.org/wiki/Allan_Snyder), who proposed a mechanism for specifying and manipulating computations that had not yet completed. In their paper, they described a programming construct called a "future" that represented the result of a computation that would be available at some point in the future.

**Promises** were introduced later as a way to represent the other side of the future relationship: the computation that produces the result. A promise is an object that represents a value that may not be available yet, but will be available at some point in the future. When the value becomes available, the promise is "fulfilled" with the value.

## 1. Definition

### 1.1 Futures
**Futures** provide a way to reason about performing many operations in parallel– in an efficient and non-blocking way. A [`Future`](https://www.scala-lang.org/api/current/scala/concurrent/Future.html) is a placeholder object for a value that may not yet exist. Generally, the value of the Future is supplied concurrently and can subsequently be used.

For this definition to make sense, we also have to define concurrency and asynchronous processes.

### 1.2 Concurrency
**Concurrency** means multiple computations are happening at the same time. In a concurrent system, multiple threads of execution can run independently of each other, potentially allowing for increased throughput, responsiveness, and efficiency.

Concurrency is often used in systems that need to handle a large number of requests or perform many tasks simultaneously. For example, a web server might use concurrency to handle multiple requests from clients at the same time, or a database might use concurrency to allow multiple queries to be executed concurrently.

### 1.3 Asynchronous processes
Asynchronous processes are processes or operations that do not block or wait for the completion of other processes before proceeding. In an asynchronous process, a request is made and the process continues to execute while waiting for a response, rather than blocking and waiting for the response before continuing.

Asynchronous processes are closely related to concurrency, as they enable concurrent execution of multiple tasks without blocking or waiting for completion. By allowing multiple tasks to execute concurrently, asynchronous processes can improve the performance and responsiveness of computer systems, as they can avoid the overhead and delays associated with blocking I/O and waiting for completion of operations.

## 2. Advantages

## 3. Examples
Let us implement a function that calculates the sum of two integers asynchronously, and returns a future that completes when the calculation is done.

### 3.1 One asynchronous calculation
Let us define a function that calculates the sum of two integers asynchronously, and returns a future that completes when the calculation is done.

The future will be waiting for the computation value, and realize to a value when the computation concludes.

Let us break our approach step-by-step:
1. We define a `Promise` associated with a `Future`. This promise will expect an integer value.
2. We the define an asynchronous task.
3. We complete the promise with the result of the calculation.
4. We start the task on a separate thread.
5. We finally call our asynchronous process using the `Await` API.
6. The `sumAsync` process call will tell us if our process terminated successfully.

##### **Code**
```Scala
import scala.concurrent.{Promise, Await, Future}
import scala.concurrent.duration._

// Define Promise
def sumAsync(a: Int, b: Int): Future[Int] = {
  val promise = Promise[Int]()

  // Start an asynchronous task to calculate the sum of the integers
  val task = new Runnable {
    override def run(): Unit = {
      val result = a + b

      // Fulfill the promise with the result of the calculation
      promise.success(result)
    }
  }

  // Start the task on a separate thread
  new Thread(task).start()

  promise.future
}

// Assign sumAsync to variable
val future = sumAsync(1, 2)

// Call using Await API
val result = Await.result(future, 10.seconds)
println(s"Sum: $result")
```

##### **Output**
```
// future: Future[Int] = Future(Success(3))
// result: Int = 3
// Sum: 3
```

This implementation considered one single calculation, but we can do the same for two calculations.

### 3.2 Two asynchronous calculations
Let us implement an addition and a multiplication asynchronously, and returns a future that completes with the result of both operations:

The process will be similar to our previous example. The only difference, is that we'll now use a `for` comprehension that combines the futures returned by the `addAsync` and `multiplyAsync` functions.

##### **Code**
```Scala
import scala.concurrent.Future
import scala.concurrent.ExecutionContext.Implicits.global

// Define operation 1
def addAsync(a: Int, b: Int): Future[Int] = Future {
  a + b
}

// Define operation 2
def multiplyAsync(a: Int, b: Int): Future[Int] = Future {
  a * b
}

// Define task
val resultFuture = for {
  sum <- addAsync(7, 5)
  product <- multiplyAsync(7, 5)
} yield (sum, product)

// Call task
val result_2 = Await.result(resultFuture, 10.seconds)
```

##### **Output**
```
// resultFuture: Future[(Int, Int)] = Future(Success((12,35)))
// result_2: (Int, Int) = (12, 35)
```

## 4. Recommendations & best practices
Futures and Promises are quite an elaborate concept that requires sufficient domain knowledge in asynchronous processing and concurrency, since a badly implemented process can crash the entire program, or worst, introduce vulnerabilities in our code.

Below are some best practices when working with these techniques:
1. **Improving parallelism for performance:** We can also use the `Future.sequence` method to execute a collection of futures in parallel. The `Future.sequence` method will execute all the futures in the collection in parallel, and return a future that completes when all the futures have completed. This can improve performance by allowing multiple tasks to execute concurrently.
2. **Avoiding blocking:** When working with futures, it is important to avoid blocking as much as possible. Blocking can cause performance issues, and defeats the purpose of using futures in the first place. Instead of blocking, use non-blocking operations and combinators like `map`, `flatMap`, `filter`, and `onComplete` to compose and transform futures.
3. **Handling errors:** Futures can fail, so it is important to handle errors properly. Use the `recover` and `recoverWith` methods to handle errors and return a default value or another future in case of failure. Use the `fallbackTo` method to try an alternative future in case of failure.
4.  **Using `ExecutionContext`:** When working with futures, it is important to use an `ExecutionContext` to execute the futures. Use the `ExecutionContext.Implicits.global` execution context for simple cases, or provide a custom execution context for more complex cases.
5. **Using Promise for more control:** Promises provide a more low-level control over the completion of futures. Use promises when you need to create a future that is not immediately available, or when you need to complete a future manually.

## 5. Use cases
1. **Using futures for network calls:** When making network calls, it is important to use futures to ensure that the calls do not block the main thread. By using futures, network calls can be made asynchronously, and the result can be returned when it becomes available. 
2. **Using promises for caching:** Promises can be used for caching values that are expensive to compute. By creating a promise and computing the value asynchronously, subsequent calls can be satisfied immediately by returning the cached value without the need to recompute it.
3. **Using futures for parallelism:** Futures can be used to execute tasks in parallel, allowing multiple tasks to execute concurrently. This can be useful for applications that require high-performance processing of large data sets.
4. **Using promises for inter-thread communication:** Promises can be used for communication between threads, allowing one thread to signal another when a value becomes available. This can be useful for implementing thread-safe data structures and synchronization primitives.
5. **Using futures for user interface updates:** Futures can be used to perform background processing and update the user interface when the processing is complete. By using futures to perform background processing, the user interface remains responsive and can provide feedback to the user during the processing.

---

# Higher-kinded types
We close this segment with a very interesting and special group of types called **higher-kinded types**. Their use as a feature of functional programming is often attributed to the computer scientist and programming language designer [Philip Wadler](https://en.wikipedia.org/wiki/Philip_Wadler), and were formally introduced in computational theory in the [ML](https://www.cs.nmsu.edu/~rth/cs/cs471/sml.html) language during the late 1970s.

## 1. Definition
Higher-kinded types, also known as type constructors or type-level functions, are a type-level abstraction that allow type constructors (such as lists or trees) to be parameterized by other type constructors.

In simpler terms, higher-kinded types are a way of defining types that can work with other types. Let us imagine a tool that can drill a hole in any kind of material, such as wood, metal, or plastic. This tool would be analogous to a higher-kinded type, since it can work with different types of materials.

In programming, higher-kinded types are used to create types that can work with other types, like lists, maps, and other data structures. This allows these types to be more generic and reusable, and makes it easier to write code that works with different types of data.

## 2. Advantages
As with many elegant forms of abstraction, the advantages for this technique are vast: 
1. **Library Design and Implementation:** Most of the use cases of higher-kinded types are found in library design and implementation. It provides the client more control over the exposed interfaces, while reducing code duplication. [Scalaz](https://github.com/scalaz/scalaz), one of the most popular Scala projects, uses higher-kinded types to extend the core Scala library for functional programming.
2. **Reusability:** Higher-kinded types allow for the creation of more generic and reusable abstractions, making it easier to write code that works with different types of data.
3. **Flexibility:** They also make it easier to create complex data structures and algorithms that can work with different types of data.
4. **Separation of concerns:** They allow for a clear separation of concerns between the data and the operations that work on that data, making code easier to understand and maintain.
5. **Modularity:** Higher-kinded types enable the creation of modular and composable code that can be easily combined and reused in different contexts.
6. **Type safety:** Finally, higher-kinded types can help prevent type errors and make it easier to reason about code by ensuring that types are used correctly and consistently throughout a program.
7. **Polymorphic Containers:** Higher-kinded types are useful when we want to create a container that can hold any type of items; we don’t need a different type for each specific content type.

Let us work on some examples to further clarify.

## 3. Examples
Since higher-kinded types are somewhat of a difficult topic without some prerequisites, we'll stick with an extremely simple case of a higher-kinded type for a specific container type, in our case, a `List` or an `Option`.

### 3.1 Implementing a higher-kinded type for a List
Before any code, we'll explain step-by-step what we will do:
1. **Define the higher-kinded type called Box:** Define a trait or abstract class with a type parameter that itself takes a type parameter. This is our higher-kinded type.
2. **Define how the Box trait should work with Lists:** It defines how the methods in the `Box` trait should behave when working with a `List`. In our case, the `ListBox` class will provide an implementation of the `first` method for a `List`.
3. **Define how the Box type should work with Vectors:** The `VectorBox` class will provide an equivalent implementation for vectors.
4. **Implement a function that can work with instances of both types:** Implement a function `findFirst` that works with instances of our higher-kinded type.

Now that we have a little bit more clarity, we can begin with our implementation:

##### **Code**
```Scala
// 1. Define the higher-kinded type called Box
trait Box[F[_]] {
  def first[A](fa: F[A]): Option[A]
}

// 2. Define how the Box type should work with Lists
class ListBox extends Box[List] {
  def first[A](list: List[A]): Option[A] = list.headOption
}

// 3. Define how the Box type should work with Vectors
class VectorBox extends Box[Vector] {
  def first[A](vector: Vector[A]): Option[A] = vector.headOption
}

// 4. Implement a function findFirst that works with instances of our higher-kinded type
def findFirst[F[_], A](box: Box[F], container: F[A]): Option[A] = {
  box.first(container)
}

// 5. Create an instance of ListBox and use it to find the first element in a list
val listBox = new ListBox()
val myList = List(1, 2, 3)
val firstElementList = findFirst(listBox, myList)

// 6. Create an instance of VectorBox and use it to find the first element in a Vector
val vectorBox = new VectorBox()
val myVector = Vector(4, 5, 6)
val firstElementVector = findFirst(vectorBox, myVector)
```

##### **Code**
```Scala
// Print both values
println(firstElementList)
println(firstElementVector)
```

##### **Output**
```
// Some(1)
// Some(4)
```

We can even go one step further, and introduce a generic implementation of the `Box` trait that can handle different container types based on the type constructor provided. However, we will need to introduce two new concepts, and one curious library called [Cats](https://typelevel.org/cats/) (*yes, there are actual cats in Cats*), aimed at providing abstractions for Scala.

For this, we will first head to our `build.sbt` file and append the following line:

##### **Code**
```Scala
libraryDependencies += "org.typelevel" %% "cats-core" % "2.6.1"
```

So that our entire build file should look like such:

##### **Code**
```Scala
import Dependencies._

ThisBuild / scalaVersion     := "2.12.8"
ThisBuild / version          := "0.1.0-SNAPSHOT"
ThisBuild / organization     := "com.example"
ThisBuild / organizationName := "example"

lazy val root = (project in file("."))
  .settings(
    name := "10-advanced-programming-techniques",
    libraryDependencies += scalaTest % Test,
    libraryDependencies += "org.typelevel" %% "cats-core" % "2.6.1"
  )
```

This should automatically download `Cats` and make it available for import. So, back in our worksheet file, we can include the following:

##### **Code**
```Scala
import cats._
import cats.implicits._
import cats.instances.list._
import cats.instances.vector._
```

Lets get this party started, shall we?

Let us define our generic implementation:

##### **Code**
```Scala
class GenericBox[F[_]: Foldable] extends Box[F] {
  def first[A](container: F[A]): Option[A] = {
    Foldable[F].reduceLeftOption(container)((a, _) => a)
  }
}
```

Where:
- `Foldable` is a typeclass in the `Cats` library that represents data structures that can be folded to a summary value. It provides a set of methods for folding and reducing data structures, such as `foldLeft`, `foldRight`, `reduceLeftOption`, `reduceRightOption`, and more.
- `reduceLeftOption` is a method provided by the `Foldable` typeclass that reduces a container of elements of type `A` to a single value of type `A`. It applies a binary function, which takes two elements of type `A` and returns a single element of type `A`, in a left-associative manner.

So in summary, the combination of `Foldable` with `reduceLeftOption` gets us the first element of a `List` or a `Vector`, which is exactly what we're looking for.

Lastly, we simply need to define our appropriate instances and call the appropriate methods:

##### **Code**
```Scala
// 2. Create an instance of ListBox and use it to find the first element in a list
val genericListBox = new GenericBox[List]
val myList2 = List(1, 2, 3)
val firstElementList2 = genericListBox.first(myList2)

// 3. Create an instance of VectorBox and use it to find the first element in a Vector
val genericVectorBox = new GenericBox[Vector]
val myVector2 = Vector(4, 5, 6)
val firstElementVector2 = genericVectorBox.first(myVector2)
```

##### **Code**
```Scala
println(firstElementList)
println(firstElementVector)
```

##### **Output**
```
// Some(1)
// Some(4)
```

So, where did our drill and materials analogy go in all of this nonsense? Simple:
- `Box` is our marvelous drill.
- `List` is a glass material.
- `Vector` is a stone material.
- `Box` can drill both *(i.e., can get their first element)*:
	- Using different drillbits in our original implementation.
	- Using the "same" drillbit in our last generic implementation.

The interesting thing is that this is just one level of abstraction. We could think that we can keep doing abstractions over traits, and we would be correct. This is precisely the power of higher-kinded types. Additionally, the Cats library provides a wide variety of tools we can use. 

## 4. Recommendations & best practices


## 5. Use cases


---

# Next steps
Scala, and functional programming in general, provides a wide variety of advanced *(and cryptically-named)* techniques and constructs we can make use of. We have to keep in mind that functional programming is heavily-based on lambda calculus, hence, the further we advance, the more mathematical theory will come to surface.

Following up from monads:
- [Monoids](https://www.baeldung.com/scala/monoids-semigroups)
- [Semigroups](https://www.baeldung.com/scala/monoids-semigroups)
- [Functors & Endofunctors](https://www.baeldung.com/scala/functors-functional-programming)
- [Category Theory & Algebraic Structures](https://medium.com/free-code-camp/demistifying-the-monad-in-scala-part-2-a-category-theory-approach-2f0a6d370eff)

Following up from high-order functions:



---

# Conclusions
We've reviewed 10 advanced programming techniques in detail, discussing their importance

---

# References
- Aa


---

# Copyright
Pablo Aguirre, Creative Commons Attribution 4.0 International, All Rights Reserved.