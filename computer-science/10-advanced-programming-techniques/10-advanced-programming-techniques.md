<article class="first">
  <div class="title">
    <h1>10 Advanced Programming Techniques</h1>
  </div>
</article>

---

[![made-with badge](https://img.shields.io/static/v1?label=Made%20with&message=Obsidian&color=7d5bed&logo=obsidian&labelColor=1a1a1a&style=flat)](https://obsidian.md/)

[![type](https://img.shields.io/static/v1?label=Type&message=blog&color=e60048&logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAYAAAByDd+UAAAAi0lEQVRIS+2WMQ7AIAhF/UNXrtP7rz2OYxeqTWxMTBUSxQVXfnzyQQKC8YExL7zAGCNbgIkIsIKVhBw4vbR7unR6Gp0LvwxXd2v+EvkdDpxWXpWlRTyi9/pABRyBJHEHSlxSadxSlV0SsVsqcUml2W/pynWxnsXNisHMRxrCl8qvH3ECnQDuOmy+0zwB4WNxmUKgwwAAAABJRU5ErkJggg==&labelColor=1a1a1a&style=flat)](https://pabloagn.com/blog/) [![category](https://img.shields.io/static/v1?label=Category&message=computer-science&color=e60048&logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAYAAAByDd+UAAAB9UlEQVRIS6VWMU7DQBDkDAQEdrAoCISCAomCL1DxC95Azy9oeQS/oOIHVFAgREFoCHGCRSzZzEU+63LZ9W6CO/vudmZ2d9Zn1pTPaDSqut2usduHw+FpFEUv7t1fk8LNAkiPDWj3+ADuTPjNvXMxWwGzLCuqqtqwh5MkiY0xEwfOAfrEKFAWUBO4DZQDXgCEqjuouvbZUanUrocpngMMVUkKtKC+WhFQUudAUd8r1PkepJ/w7Tysn4uzkNJlascF9WOASAki6w0xrn19b3Gpps5y3kRfJADPZgr9gJSP0EgDHDiQ/Mp50PfxAmDtuQhsZmb/z0OVhwSkmGrSGp5bGRDp3EFaJ5JaiahdZ2vYNj/JkWVMgW7sgNw2yOW+99gacp7TeFE72OcUrgo4Ho93+/3+D5T9QmGHm0BNSnHgMI7jj9Ai2tElZGCK9S3S+GA4BcNNydBaIuEstu/iLJWCa+pLDm+Nz+xQAsBenucnRVG8asFq0s/Yf9YoVAI21wyn3N4I7M1A8ijWHwB42XrFqIO9YfMRlVqqyXC5ukED3nIEVJcoBXv1lmWa5gIpeeQioyTWVj1uXf0DpgKUZbmfpunXKnVnU9rWDKiTHRSDNkDu36iqIQK/Q+mxU8sBYniL/1EVoJ9Wqwo/5x6Cf9YKv6Em1XbNH5bGfSwvuRe1AAAAAElFTkSuQmCC&labelColor=1a1a1a&style=flat)](https://pabloagn.com/categories/computer-science/) [![technologies](https://img.shields.io/static/v1?label=Technologies&message=Python&color=e60048&logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA4AAAAOCAYAAAAfSC3RAAAACXBIWXMAAAsTAAALEwEAmpwYAAAA1klEQVR4nM2RMW7CUBBEnUikIQUIlBJxrrQgJG7ABRBnoUkaWhpoUgWJlgNYbvz/G1dUi1ayoy87rpOtVrszs6OdLPtXlef5UNJXjHHcCwohjMzsKZ3FGN+Bq/e+c0xHGfiWtEznkg6SNnW/dIxjs0YJ2AMnM3tJSFPgHkKY17gBcAQ+zOw5A3aSbsCkdW0NnNOZY2rstpcInJ3cS/SzwGdqtSzLmdusquqtIXWsehVF8QpcJK1qmxt/TMv6wjE/z0leP27i8Ag8inT/axxtAQ+9o/zn9QD3JOiyTjnQEQAAAABJRU5ErkJggg==&labelColor=1a1a1a&style=flat)](https://pabloagn.com/technologies/) [![website article](https://img.shields.io/static/v1?label=Website&message=Post%20Link&color=e60048&logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAYAAAByDd+UAAAACXBIWXMAAAsTAAALEwEAmpwYAAAB+ElEQVR4nO2VOYgUURCGR/BAI4MN1EwjI89EMDYQvNBNNNlcE0VBUdlUUSMjj2BF2UDRePDAwGzNF2GNPIYd8Hjv/6YnEHSf/FIDPTJiu4nJFBTd1Kv6/nrVBd1q/S8DJiU9AmaBm5LOSjoATPwDY0LSQUnnzDArmJOjkqclvQceSHohaR6oJC1JeiPprqT9pZSVg5pSyirH4sw5S1EzbwZwP5jTIwWBdj1meEppZ6/XOyXpCdCX9Am4Fv45Yo+Bk1VV7ag3FNz2kKC7yznvHiX4u3U6nXU55xPAW7vfHfvLmNtmW8NaFux67k0Ea03esTfJJQTj23bHgiNtPNK6jZem3Wpg46Wp23hp2q0GNl6axksjaRGYkXRF0mnHq6ra2HSk/X5/k6RDks6YEazFPwnuBS5KuirptqTnkj4CJZ4zwNFSytqBoP/2wDHgXi33A/BM0i2zzDR7SBC4LGlPr9fb5huVUlYMus45b5E0FYJfgQS8C8/Al7jJVEpp86DODLPMNDs0up7xXBQZVKLLb8CCpIfA+ZzzvpTS+lLKGuAI8DT8cClltc+c49yoWQjGL140ao25oW8QXW1IKe3KOR8Hbkh66ZtI+i7plaG+iR244JjP3HDkXnetGWbVp9XYopHtHgvwWtIPu9+BSx7bssBNDdhqX07xT/Jbz1SBBDGHAAAAAElFTkSuQmCC&labelColor=1a1a1a&style=flat)](https://pabloagn.com/blog/programming-best-practices-writing-better-code/)

We could spend our entire developer's life using just the basic concepts of any programming language we choose to learn, and there's nothing wrong with that; in many cases, very powerful concepts have already been abstracted for us, providing a great out-of-the-box experience, particularly with languages such as Python, R and JavaScript. However, a programmer's horizon would be limited if we didn't have advanced techniques to play with, because in the end, programming is about solving problems, and the more creative, the better. These techniques are not only there to make us more efficient in writing code, but also in thinking out of the box by using more sophisticated tools.

In this Blog Article, we'll discuss 10 advanced programming techniques that provide different functionalities to our code; they can make our syntax more elegant, expressive, performant, compact, modular, and a bunch of different attributes that we probably didn't know could be included in the first place. We'll focus on Scala since many of the techniques are closely related with functional programming.

We'll start by providing historical context on each technique, following a formal definition, main advantages, a set of hands-on examples, recommendations & best practices, and popular real-world use-cases.

We'll be using Scala scripts which can be found in the [Blog Article Repo](https://github.com/pabloagn/blog/tree/master/computer-science/10-advanced-programming-techniques).

---

# Table of Contents
- [What to expect](#what-to-expect)
- Preparing our environment
- Tail recursion
- Higher-order functions
- Currying
- Monads
- Lazy evaluation
- Pattern matching and extractors
- Implicits and type classes
- Continuation-passing style (CPS)
- Macros and metaprogramming
- Higher-kinded types
- Next steps
- [Conclusions](#conclusions)
- [References](#references)
- [Copyright](#copyright)

---

# What to expect
There are simple techniques such as code refactoring, modularization, and anonymous functions we can use to instantly make our code better. However, this segment will introduce advanced programming concepts. Consequently, it'll be best if we already have some previous knowledge of functional programming and ideally, Scala, Haskell, or a similar language.

We will not include any installation process for Scala neither for Python, since this is out of the scope of this segment (*a full Scala 3 installation along with sbt and a preferred IDE is assumed*). We will also not discuss basic principles such as syntax and compiling, since this is also out of the scope of this segment. Instead, we'll introduce 10 techniques and explain why they're useful, go over each one in detail, provide a set of examples in Scala & Python, depending on the implementation, and provide some recommendations for using each technique, as well as use-cases and best practices.

---

# Preparing our environment
As mentioned, we'll be using Scala for this segment.

We'll first head to the directory where we wish our project to be created in:

##### **Code**
```PowerShell
cd Projects
```

We'll then create a new Scala project by executing the following command in our terminal:

##### **Code**
```PowerShell
sbt new sbt/scala-seed.g8
```

We'll name our project whenever sbt requests the project name.

We'll then open our preferred IDE, import the newly-generated build, and create a new worksheet inside `/projectname/src/main/scala`

##### **Code**
```PowerShell
cd /projectname/src/main/scala
```

##### **Code**
```PowerShell
New-Item -ItemType File -Path ".\Sheet.worksheet.sc"
```

We'll mainly be working in our worksheet. However all the implementations discussed in this segment can also be included in a `.scala` file, given that we include the main Object and the main function inside a `Main.scala` file, where `Main` can be any name. 

Now that we have everything ready, we'll move to the first technique: Tail recursion.

---

# Tail recursion
The idea of **tail recursion** has been around for a long time, but its specific use in functional programming is often credited to the computer scientist Daniel P. Friedman and his colleagues.

In the late 1970s and early 1980s, Friedman and his colleagues developed a series of programming languages based on Scheme, a dialect of Lisp. These languages included a number of advanced features for functional programming, including tail recursion optimization.

## 1. Definition
Tail recursion is a recursive technique where the recursive call is the last operation performed in the function.

This means that the function's stack frame can be reused for the next recursive call, rather than creating a new stack frame for each recursive call; in simpler terms, the function's stack size remains constant and does not grow with each recursive call, even if the function recurses deeply.

## 2. Advantages
Overall, a recursive approach is more elegant and often times used to simplify complex problems. It also supports the idea of immutability (*variables do not change value at any time*), and is generally optimal for helping facilitate modular design by breaking a complex problem into smaller sub-problems.

More specifically, tail recursion implements a safer way to perform recursion; it avoids the potential of stack overflow errors by keeping the stack as constant. This means that we can solve big problems without exceeding maximum recursion depths and/or getting memory errors. 

## 3. Examples
Let us design 4 tail-recursive implementations, starting with the simpler ones. In every case, we will include a special annotation, `@tailrec`. This annotation ensures that the compiler optimizes our recursive implementation as a tail recursion problem.

It also explicitly tells the reader that our implementation is a tail-recursive one, and should be treated as such *(its important to note that the Scala compiler will most probably treat our function as tail-recursive even if we omit the annotation. The annotation just makes it explicit and ensures that the function is optimized for this end)*.

### 3.1 Sum of a list
Let us implement a tail-recursive function that calculates the sum of all elements in a given list of integers. The function should take a list as input and return the total sum of its elements.

What we'll do here, is the following:
1. Import the `tailrec` annotation.
2. Define two functions:
	- The first outer function will accept a list as its only input.
	- The second nested function will accept our list and a counter that we will use to keep track of the summation.
3. Call our outer function with a list.

We first import the `tailrec` annotation, and define our outer and nested recursive functions:

##### **Code**
```Scala
import scala.annotation.tailrec

def recursiveSum(list: List[Int]): Int = {
    @tailrec
    def sumItems(list: List[Int], counter: Int): Int = {
        if (list.isEmpty) counter
        else sumItems(list.tail, counter + list.head)
    }
    sumItems(list, 0)
}
```

If we noticed, the `@tailrec` annotation is referring to the nested function. This is because the outer function is not a tail-recursive function. In fact, it's not even a recursive function; it simply calls the nested function when called.

We can then call out outer function with a simple list first:

##### **Code**
```Scala
recursiveSum(List(1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
```

##### **Output**
```
// res1: Int = 55
```

We can try our function with a larger number:

##### **Code**
```Scala
recursiveSum(List.range(1, 100000))
```

##### **Output**
```
// res2: Int = 704982704
```

But what if we try it with an even larger number?:

##### **Code**
```Scala
recursiveSum(List.range(1, 1000000000))
```

##### **Output**
```
java.lang.OutOfMemoryError: Java heap space: failed reallocation of scalar replaced objects
```

In this case, we get a heap memory error. But didn't we just say that tail recursion maintained stacks as constant, meaning we should not have recursion depth errors? Yes, that's right, but the problem here is not a stack overflow error.

When we encounter a large list such as the one we defined in our last example, the compiler may have trouble allocating space for the object. While using tail recursion can help avoid stack overflow errors, it doesn't necessarily prevent memory heap errors; in some cases, a tail-recursive function may still consume a large amount of memory if it creates many intermediate objects that are not garbage collected.

We can see that although extremely useful, tail recursion has limitations. This can be solved by implementing other techniques:
- Processing the list in smaller chunks.
- Using lazy evaluation.
- Use primitive types.

### 3.2 Factorial calculation
Let us implement a tail-recursive function that calculates the factorial of a given non-negative integer $n$. The factorial of $n$ (*denoted as $n!$*) is the product of all positive integers less than or equal to $n$. For example, $5! = 5 × 4 × 3 × 2 × 1 = 120$.

The main problem with a factorial calculation, is that it grows fast. In fact, a factorial will eventually grow faster than $2^{n}$ and $e^{n}$ (*but not $n^n$*), so we have to find another numeric type that will allow us to store big integers; if we select the conventional `Int` type, the type will overflow and result in negative values, or in our case, 0.

As with the previous example, we will import the `@tailrec` annotation, and define two functions:
1. Import the `tailrec` annotation.
2. Define two functions:
	- The first outer function will accept an `Int` type as its only input.
	- The second nested function will accept our `Int` type value, and a counter with `BigInt` type that we'll use to keep track of the factorial operation.
3. Call our outer function with an integer value.

We first import the `tailrec` annotation, and define our outer and nested recursive functions:

##### **Code**
```Scala
def factorialCalc(n: Int): BigInt = {
    @tailrec
    def factorialItems(n: Int, counter: BigInt): BigInt = {
        if (n == 0) 1
        else if (n == 1) counter
        else factorialItems(n-1, n * counter)
    }
    factorialItems(n, 1)
}
```

We can start by calling our function using an edge case, which in our case will be 0:

##### **Code**
```Scala
factorialCalc(0)
```

##### **Output**
```
// res1: BigInt = 1
```

We can then call out outer function with a small integer:

##### **Code**
```Scala
factorialCalc(4)
```

##### **Output**
```
// res2: BigInt = 24
```

We can try our function with a larger number:

##### **Code**
```Scala
factorialCalc(10)
```

##### **Output**
```
// res3: BigInt = 3628800
```

And even with a larger number:

##### **Code**
```Scala
factorialCalc(100)
```

##### **Output**
```
// res4: BigInt = 93326215443944152681699238856266700490715968264381621468592963895217599993229915608941463976156518286253697920827223758251185210916864000000000000000000000000
```

We can see that the last output doesn't even fit in a single line. If we had not used `BigInt`, we would've gotten a type overflow.

### 3.3 Fibonacci sequence
Let us implement a tail-recursive function that returns the $n^{th}$ number in the Fibonacci sequence. The Fibonacci sequence is a series of numbers in which each number is the sum of the two preceding ones, starting from $0$ and $1$. For example, the sequence goes: $0, 1, 1, 2, 3, 5, 8, 13$, and so on.

Similar to our previous examples, we will proceed as follows:
1. Import the `tailrec` annotation.
2. Define two functions:
	- The first outer function will accept an `Int` type as its only input.
	- The second nested function will accept our `Int` type value, a number `next` with `BigInt` type, and a number `current` with `BigInt` type.
3. Call our outer function with an integer value.

We define a and b as follows:
- `next`: Will be the previous number in our sequence.
- `curr`: Will be the current number in our sequence.

We first import the `tailrec` annotation, and define our outer and nested recursive functions:

##### **Code**
```Scala
def FibCalc(n: Int): BigInt = {
    @tailrec
    def fibItems(n: Int, next: BigInt, current: BigInt): BigInt = {
        if (n == 0) current
        else fibItems(n-1, next + current, next)
    }
    fibItems(n, 1, 0)
}
```

Let us exemplify this calculation using a table:

| Index | Next                | Current      |
| ----- | ------------------- | --------- |
| 7     | 1                   | 0         |
| 6     | 1 (`next` + `current`)  | 1 (`next`)  |
| 5     | 2 (`next` + `current`)  | 1 (`next`)  |
| 4     | 3 (`next` + `current`)  | 2 (`next`)  |
| 3     | 5 (`next` + `current`)  | 3 (`next`)  |
| 2     | 8 (`next` + `current`)  | 5 (`next`)  |
| 1     | 13 (`next` + `current`) | 8 (`next`)  |
| 0     | 21 (`next` + `current`) | 13 (`next`) |

###### Table N: Tail-Recursive Fibonacci Sequence For Index = 7

A step-by-step explanation:
1. At first, we initialize our index with 7, our `next` value with 1, and our `current` value with 0.
2. We then subtract one from our index, set our new `next` to `next` + `current`, and set our new `current` to `next`.
3. We do this until our index is 0.
4. We finally return `current` as our final value.

What we're doing here is keeping track of three sequences at the same time:
- A decreasing sequence (`index`).
- An increasing sequence (`current`).
- The calculation (`next`).

The key thing here, is that we don't return the `next` value; instead, we return the `current` value, which is the `next` value from the previous step.

We can test our algorithm with some smaller and bigger numbers:

##### **Code**
```Scala
// Edge case call
FibCalc(0)

// Small integer call
FibCalc(5)

// Extense call
FibCalc(10)

// Even bigger call
FibCalc(1000)
```

##### **Output**
```
// res6: BigInt = 0

// res7: BigInt = 5

// res8: BigInt = 55

// res9: BigInt = 43466557686937456435688527675040625802564660517371780402481729089536555417949051890403879840079255169295922593080322634775209689623239873322471161642996440906533187938298969649928516003704476137795166849228875
```

### 3.4 Exponentiation
Let us implement a tail-recursive function that calculates the result of a given number (*base*) raised to the power of another number (*exponent*). The function should take two integer inputs, base and exponent, and return the result as a single integer.

We'll take a similar approach to our previous implementations:
1. Import the `tailrec` annotation.
2. Define two functions:
	- The first outer function will accept two `Int` type variables, `base` and `exp`.
	- The second nested function will accept our two `Int` type variables, `base` and `exp`, and a counter with `BigInt` type.
3. Call our outer function with two integer values.

We first import the `tailrec` annotation, and define our outer and nested recursive functions:

##### **Code**
```Scala
def ExpCalc(base: Int, exp: Int) : BigInt = {
    @tailrec
    def ExpItems(base: Int, exp: Int, counter: BigInt): BigInt = {
        if (base == 0) 0
        else if (exp == 0) 1
        else if (exp == 1) counter
        else ExpItems(base, exp - 1, base*counter)
    }
    ExpItems(base, exp, base)
}
```

We will then call our function with smaller and bigger numbers:

##### **Code**
```Scala
// Edge case call
ExpCalc(0, 0)

// Small integer call
ExpCalc(2, 2)

// Extense call
ExpCalc(8, 4)

// Even bigger call
ExpCalc(14328, 5)
```

##### **Output**
```
// res1: BigInt = 0

// res2: BigInt = 4

// res3: BigInt = 4096

// res4: BigInt = 603848322560489914368
```

## 4. Recommendations & best practices
As we saw from our previous examples, there are some common patterns when using recursion:
- We properly define our edge or boundary case(s). This case will be our stopper, and must be thought of carefully. Else, the implementation might enter an infinite loop and/or result in a memory error.
- We recursively call our function using some kind of modified parameter.

More particularly, with tail-recursion most of the times we will need to define a helper function that will provide some sort of counter or accumulator. This is because, in order to avoid any operation at the end besides the recursive call, we recursively call our function with modified arguments by using a counter to keep track. Else, we would effectively loose important tracking parameters in favor of our accumulator.

Of course, as we also saw, tail recursion is not infallible. Below are some recommendations to follow in order to ensure proper execution:
- **Ensuring tail-call optimization:** For this approach to work, we must place the recursive call as the last operation in the function, so the compiler can optimize it into a loop, avoiding stack overflow issues. We must particularly ensure that no further operations depend on the result of the recursive call.
- **Using accumulator variables:** We already mentioned counter or accumulator variables. They are used to carry the intermediate results through the recursion, reducing the need for additional computation or memory overhead. We can pass these variables as parameters in our recursive implementation.
- **Keeping it simple:** Tail-recursive functions should be designed with simplicity in mind; overcomplicating them defeats the purpose of elegance and clarity. We must avoid complex logic or nested conditional statements, as they can make the code harder to understand and maintain.
- **Using helper functions:** We already discussed this point. Using helper functions, also known as inner functions, to hide implementation details and encapsulate the tail-recursive logic can make the code more readable and maintainable. It also makes it possible to implement many tail-recursive functions in the first place.
- **Documenting our code:** Clearly document our tail-recursive functions, including a description of the function, input parameters, return values, and any edge cases. This will make it easier for others (*and ourselves*) to understand and maintain the code.
- **Testing edge cases:** This is a big one. We must thoroughly test our tail-recursive functions with a variety of input values, including edge cases such as negative numbers, zero, and large numbers. This will help ensure the correctness and stability of our implementation.
- **Considering alternatives:** While tail recursion is an effective technique for certain problems, it may not always be the best approach. We must consider alternative algorithms or data structures that might offer better performance or simplicity in some cases.
- **Understanding language/compiler limitations:** Some programming languages or compilers may not support tail-call optimization. Be aware of the limitations of the language or compiler we're are using, and consider alternative approaches if tail-call optimization is not supported or guaranteed.

## 5. Use cases
Apart from the mathematical applications we already reviewed, this technique can be used in a variety of real-life situations:
- **Tree traversal:** In data structures like trees or graphs, tail recursion can be used to traverse the structure in depth-first or breadth-first order efficiently. This can be particularly useful in scenarios like searching, sorting, or parsing XML/JSON files.
- **Parsing and tokenization:** Tail recursion can be utilized in compiler design, particularly in parsing and tokenization processes. When converting a source code file into tokens or parsing an expression, tail recursion can optimize memory usage and improve performance.
- **String manipulation:** In text processing, tail recursion can be employed for string manipulation tasks like string reversal, pattern matching, or substring search, providing an efficient and resource-friendly solution.
- **File and directory operations:** Tail recursion can be applied in file system operations such as directory traversal, file search, or file copying, to optimize memory consumption and improve performance.
- **Optimization problems:** Tail recursion can be applied in dynamic programming or other optimization problems, where a problem is broken down into smaller subproblems and solved iteratively. This can lead to efficient solutions that avoid redundant calculations and save memory.

Additionally, tail-recursion lets us think of problem solving in a different way.

---

# Higher-order functions
**Higher-order functions** are often attributed to the mathematician and computer scientist [Alonzo Church](), who developed the lambda calculus in the 1930s. 

## 1. Definition
Higher-order functions are one of the pinnacles of functional programming. They are very simple, yet extremely elegant and, well, functional. A higher-order function is one that accepts and/or returns a function instead of a value. In other words, a higher-order function is one that operates on functions.

This concept is easy to implement in Scala, since all functions are first-class citizens of the value type (*first-class values*), meaning they can be treated as values and be passed as arguments to other functions, returned as values from functions, and assigned to variables.

The basic syntax of a higher-order function is as follows:

##### **Code**
```Scala
// Higher-order function
def myfun(f: Int => Boolean, n: Int): Boolean = {
    f(n)
}

// Parameter function
def f(n: Int): Boolean = {
    n >= 1
}

// Higher-order function call
myfun(f, 1)
```

1. We first define our higher-order function that will accept a function `f`.
2. We then define a function f that accepts an `Int` value, and returns a `Boolean` value.
3. Lastly, we call our higher-order function with `f` as argument.

## 2. Advantages
Higher-order functions are basically an extra layer of abstraction done in a functional style. They are extremely useful when working with repetitive tasks, and can be used in conjunction with tail-recursive methods, providing an elegant and minimalist way to handle complex operations.

They are also extremely useful when flexibility and conciseness are required. Additionally, higher-order functions can help separate concerns by allowing us to separate the logic of a function from its implementation details.

As with any level of abstraction, this concept is tricky to grasp as first. Let us try to perform some simple examples in order to further clarify.

## 3. Examples
We'll review two examples of higher-order function implementations: The first one will be a simple case, while the second one will be more elaborate.

### 3.1 Single verification of a list
Let us implement a function that accepts a list of integers and a predicate function (`Int => Boolean`). The function should return the number of occurrences that satisfy the given predicate. The predicate function evaluates to `true` if the number is even.

We can follow the steps below:
1. Define an outer function that will accept a checker function, and our list containing the target numbers.
2. Define an inner function that will recursively go over all the numbers in the list, and pass then as arguments to our predicate function.
3. Define a predicate function that will evaluate if a given number is even.
4. Return the total number of occurrences by using a counter.

##### **Code**
```Scala
def checkList(checkerEven: Int => Boolean, list: List[Int]): Int = {
    def countElements(checkerEven: Int => Boolean, list: List[Int], counter: Int): Int = {
        if (list.isEmpty) counter
        else {
            if (checkerEven(list.head)) countElements(checkerEven, list.tail, counter + 1)
            else countElements(checkerEven, list.tail, counter)
        }
    }
    countElements(checkerEven, list, 0)
}

def checkerEven(target: Int): Boolean = {
    target % 2 == 0
}
```

If we call our higher-order function, we should get the following:

##### **Code**
```Scala
checkList(checkerEven, List(1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
```

##### **Output**
```
// : Int = 5
```

### 3.2 Variation of a summation
Let us define a function that accepts two integers, $a$, $b$, as upper and lower bounds, an integer $x$ for performing addition and product operations, and two functions as arguments. The function calculates a variation of the summation operation, where the first argument function will perform the addition operation for each term of the summation between $a$ and $b$, while the second one will calculate the product of the result of the previous operation with the parameter $x$.

Similar to the previous example, we can follow the steps bellow:
1. Define the higher-order function that will recursively call all the elements of the list.
2. Define a second function that will perform the addition operation.
3. Define a third function that perform the product operation.
4. Return the resulting value.

##### **Code**
```Scala
def sumNumbers(applyProduct: (Int, Int) => Int, applyAddition: (Int, Int) => Int, a: Int, b: Int, x: Int): Int = {
    if (a > b) 0
    else applyProduct(applyAddition(a, x), x) + sumNumbers(applyProduct, applyAddition, a + 1, b, x)
}

def applyProduct(n: Int, x: Int): Int = {
    n * x
}

def applyAddition(n: Int, x: Int): Int = {
    n + x
}
```

Let us explain the process step-by-step:
1. We define our three functions: `sumNumbers`, `applyProduct`, and `applyAddition`.
2. `applyProduct` takes two `Int` arguments, `n` and `x`, and returns their product (`n * x`).
3. `applyAddition` takes two `Int` arguments, `n` and `x`, and returns their sum (`n + x`).
4. `sumNumbers` takes five arguments: two function arguments `applyProduct` and `applyAddition`, which both have the type signature `(Int, Int) => Int`, and three `Int` arguments `a`, `b`, and `x`.
5. In `sumNumbers`, we define a conditional expression:
	- If `a > b`, the function returns `0`.
	- Else, the function calculates `applyProduct(applyAddition(a, x), x)` and adds it to a recursive call of `sumNumbers` with the same function arguments and `a` incremented by `1`.

We can finally call our function:

##### **Code**
```Scala
sumNumbers(applyProduct, applyAddition, 2, 3, 2)
```

##### **Output**
```
// : Int = 18
```

## 4. Recommendations & best practices
This technique has many flavors, and can be performed using named as well as anonymous functions. As we can see, it can become confusing if we don't do things in a clear way. This is why there are some best practices we can follow:
1. **Using clear naming**: It's best that we always use descriptive names for higher-order functions and their arguments to improve code readability and maintainability.
2.  **Using type annotations**: We can also specify types for function arguments and return values to ensure type safety and make the code more understandable.
3.  **Keeping functions small and focused**: Each function should have a single responsibility. This makes it easier to understand, test, and reuse the functions.
4.  **Leveraging immutability**: As is tradition with functional programming, using immutable data structures and avoiding side effects in higher-order functions can reduce the risk of bugs and improve code predictability.
5.  **Using standard library functions**: We can also take advantage of built-in higher-order functions like `map`, `filter`, and `reduce` instead of implementing custom iterations. This leads to cleaner, more idiomatic code.

## 5. Use cases
1.  **Data transformation**: To transform data in a collection, we can take advantage of higher-order functions like `map` that apply a specific function to each element.
2.  **Filtering data**: When it comes to refining data, we can use higher-order functions such as `filter` to selectively include or exclude elements based on a given condition.
3.  **Data aggregation**: Combining elements in a collection into a single result becomes easier when we employ higher-order functions like `reduce` or `fold` for custom aggregations like sums or products.
4.  **Function composition**: By embracing higher-order functions, we can create new functions through the combination or chaining of existing ones, which enhances code reusability and modularity.
5.  **Event handling**: In event-driven programming, we can harness higher-order functions to define and manage event listeners, simplifying the process of attaching or detaching specific behaviors to events.

---

# Currying
**Currying** is a technique that was introduced in the 1930s by the mathematician and logician [Haskell Curry](), as part of his work in combinatory logic. The concept of currying was further developed in the 1950s and 1960s by other mathematicians and computer scientists, such as [Alonzo Church](https://en.wikipedia.org/wiki/Alonzo_Church) and [John McCarthy](https://en.wikipedia.org/wiki/John_McCarthy_(computer_scientist)). It was then popularized in functional programming languages such as Lisp and ML.

## 1. Definition
Currying is a concept closely related with higher-order functions, because it builds on them. Currying consists of breaking down a function that takes multiple arguments into a series of functions that take one argument each. The functions can then be called sequentially using parenthesis.

## 2. Advantages
There are multiple advantages when working with currying techniques:
1.  **Modularity:** The functions can be broken down into smaller, more manageable parts. This can make code easier to read, write, and maintain.
2.  **Flexibility:** Currying provides flexibility by allowing functions to be partially applied or composed with other functions. This enables developers to create new functions from existing ones in a modular and flexible way.
3.  **Code reuse:** Currying allows generic functions to be parameterized with specific functionality. This reduces code duplication and promotes code reuse.
4.  **Type safety:** Currying provides type safety by ensuring that functions only accept arguments of the correct type. This reduces the likelihood of runtime errors and makes code more robust.
5.  **Partial evaluation:** We can perform partial evaluation by allowing functions to be evaluated with some of their arguments, while others are left to be supplied later. This can improve performance by reducing the need for repeated computations.

## 3. Examples
We'll perform two examples, the first one including a curried function, and the second one including a curried call to two functions.

### 3.1 A curried addition function
Let us implement a curried function called `add` that takes two integer arguments, `x` and `y`, and returns their sum. The function should be defined using multiple parameter lists, where the first parameter list takes one integer argument `x`, and the second parameter list takes one integer argument `y`. The function should be flexible and modular, allowing it to be partially applied or composed with other functions.

The steps to follow are straightforward:
1. Implement a curried function.
2. Partially call the curried function.
3. Complete the curried function call in a new line.

##### **Code**
```Scala
/ Define a curried function
def sumNums(x: Int)(y: Int) = {
    x + y
}

// Partial call
val first_call = sumNums(7) _

// Complete call
val second_call = first_call(3)
```

##### **Output**
```
// : Int => Int = <function1>
// : Int = 10
```

We use the `_` placeholder to indicate that we want to partially apply a function with one or more arguments. The `_` placeholder is used in place of the argument that we want to partially apply, and it indicates that we're creating a new function that takes the remaining arguments.

The type of `first_call` is actually a function we can apply to a given value. If we hover over `first_call` below the `Complete call` line, it will actually tell us the following:

```
def apply(v1: Int): Int
Apply the body of this function to the argument.
**Returns:** the result of function application.
```

This is interesting, because we can apply `first_call` to any other value, and even a function. 

### 3.1 A curried call using two functions
Let us define a curried function that computes the sum of two values, $x$ and $y$, and then squares this result.

This one is a little bit trickier, since we need to first define a function that accepts the following:
- A function that will square the result.
- Two integers, $x$ and $y$, that will be operated on.
- A squaring function that will square the result.

Let us begin with the first one:

##### **Code**
```Scala
def sumInts(squareInt: Int => Int)(x: Int, y: Int): Int = {
    squareInt(x + y)
}
```

We can already see that the syntax is slightly different. What we're doing is:
- Define a curried function `sumInts` that has two parameter groups.
	- The first group is actually a function `squareInt` which accepts an integer and returns an integer.
	- The second group is our $x$, $y$ pair.
	- The function returns an integer type.
- Call the `squareInt` function on the sum of the $x$, $y$ value pair.

We then define our `squareInt` function:

##### **Code**
```Scala
def squareInt(a: Int): Int = {
    a*a
}
```

We can finally call our functions:

##### **Code**
```Scala
sumInts(squareInt)(2, 3)
```

This syntax is also slightly unconventional. Let us explain it:
- We first call our `sumInts` function with the first group of parameters *(i.e., the `squareInt` function)*.
- We then call our new composed function with the numbers we wish to operate on.

We get the following output in return:

##### **Output**
```
// : Int = 25
```

As with the previous example, we could've also performed a partial call, and then use our new function as required:

##### **Code**
```Scala
val applySumSquare = sumInts(squareInt) _
```

##### **Code**
```Scala
applySumSquare(2, 3)
```

##### **Output**
```
// : Int = 25
```

## 4. Recommendations & best practices
1.  **Identifying suitable use cases**: We must consider using currying when partial application, function specialization, or improved type inference would benefit our code. 
2.  **Ordering parameters thoughtfully**: We can arrange parameters so that the ones most likely to be reused or pre-filled are in the initial parameter groups, making it easier to create partially applied functions.
3.  **Avoiding overusing currying**: We must be cautious not to overuse currying, as it can make the code harder to read and understand when used inappropriately.
4.  **Combining with other functional techniques**: We can enhance our code by combining currying with other functional programming techniques, such as function composition and higher-order functions.
5.  **Keeping function signatures clear**: When using currying, we must ensure that the function signatures remain clear and understandable, by providing appropriate type annotations and using descriptive parameter names.

## 5. Use cases
1.  **Reusable validators**: We can use currying to create reusable validation functions for user inputs in web applications, by partially applying common validation rules while leaving the input value to be applied later.
2.  **Customized event handlers**: In event-driven programming, we can use currying to create customized event handlers that have some pre-filled arguments, such as the event type or specific settings, allowing for flexibility and code reuse.
3.  **Configurable logging**: We can leverage currying to build configurable logging functions where the log level, message format, or output destination can be partially applied, making it easy to create specialized loggers with minimal code changes.
4.  **Flexible arithmetic operations**: In mathematical computations, we can utilize currying to create flexible arithmetic operations, such as specialized adders or multipliers, by partially applying one operand and allowing the other to be applied later.
5.  **Tailored data transformations**: In data processing pipelines, we can harness currying to generate tailored data transformation functions with specific rules or configurations partially applied, streamlining the process of applying these transformations to various data sets.

---

# Monads
**Monads** are a concept in functional programming originally developed in the 1960s in category theory, a branch of mathematics that studies abstract structures and relationships between them.

The concept in the context of functional programming was rediscovered by the computer scientist [Eugenio Moggi](), who published a paper in 1989 called "*[Computational Lambda Calculus and Monads](https://www.cs.cmu.edu/~crary/819-f09/Moggi89.pdf)*". Monads were first introduced in Haskell in the early 1990s, and still comprise a core part of the language.

## 1. Definition
A monad, is the English translation for *"monada"* in Spanish, which interestingly enough, means cute little thing (*that is, if we eat the accent since my keyboard has US layout and [Keychron](https://www.keychron.com/) is to blame*) (*And no, its not a referral link, I really love my keyboard, which I'm sure cannot be said for my family hearing the thick thock at 6 am*).

Jokes aside, a monad is a design pattern used to encapsulate and manipulate computations that produce values of a specific type, abstracting away the details of the computation. 

In simpler terms, a monad can be thought of as a "*container*" or a "*wrapper*" that holds a value and provides a standardized way to perform operations on that value. Monads are of huge help when chaining computations and handling side effects, making it easier to reason about and structure code.

Monads exist in various languages *(mainly in functional ones)*, such as Haskell, Scala, F#, Swift, JavaScript, Kotlin, [Rust](https://pabloagn.com/blog/rust-for-beginners/), and even Python. While some languages have built-in support for monads, many others can utilize monadic concepts through third-party libraries or by implementing monad patterns manually.

## 2. Advantages
Monads were introduced to computational theory as a way to handle side-effects; if we have a chain of operations represented by functions, that will eventually result in a return value, monads make sure that, if a given step produces an unintended value (*such as `null` or `nil` values*), there will be an appropriate handling for that, thus avoiding an error return.

More specific, in functional programming we usually want to define our chains of operations using functions. If we would like to execute a given chain of functions without errors, we could define an intermediate function that handles the types behind the scenes *(sort of a checker)*, so that when we call our chained functions and the first function returns an "*unexpected*" value, we can handle that within our chain. More importantly, we're abstracting this concept into a function that can be reused in as many intermediate steps as we would like. This could potentially save us a lot of time of exception writing.

Another great example in functional programming is the purity of functions. A function is pure if it returns the same value over and over again. An impure function might return different values when calling with the same input. We can employ monads to ensure that impure functions return a boxed value *(i.e., a value of a primitive type that has been wrapped or "boxed" into an object of a corresponding reference type)*.

So why go all about this fuzz, when we can simply build an exception handling with conditionals or assertions? Well, there are some advantages to monads that the previous simply cannot offer:
- **Explicit error handling:** Monads like `Option`, `Either`, and `Try` make error handling more explicit, as they encode the possibility of failure directly in the type system.
- **Improved code readability:** They can also make code more readable and maintainable by abstracting away error handling boilerplate. Chaining monadic operations using `flatMap`, `map`, and `for` comprehensions can lead to cleaner and more concise code compared to nested conditionals or `try`-`catch` blocks.
- **Encapsulation of side effects:** Monads can be used to encapsulate side effects, making it easier to reason about the code. This is particularly useful in functional programming, where immutability and the absence of side effects are desired properties. Monads like `IO` in Haskell or `Task` in Scala help manage side effects in a controlled manner, without breaking the functional programming principles.
- **Composability:** Monads are highly composable, allowing us to chain multiple operations together in a clean and concise way. This can lead to more modular and reusable code compared to using conditionals and assertions. Additionally, monads can be used with higher-order functions and other functional programming techniques.
- **Avoiding exceptions:** Exceptions can be expensive in terms of performance, and they can make it more difficult to reason about the control flow of our program. By using monads, we can return a value representing success or failure, and handle errors in a more controlled and predictable manner.

Monads are confusing if explained with simple words. This is why we'll spend appropriate time exploring one of them with a simple example.

## 3. Examples
Let us explore one case, where we have a chain of two functions, and would like to ensure proper and smooth execution between them:

### 3.1 An undefined operation
We would like to pack two expressions into two separate functions, and perform them consecutively: 
- Value A divided y Value B equals Value C
- Value C divided by Value D equals E

##### **Code**
```Scala
// Unsafe division one
def unsafeDivOne(UnsafeDivTwo: (Double, Double)  => Double, a: Double, b: Double, d: Double): Double = {
    UnsafeDivTwo(a, b) / d
}

// Unsafe division two
def UnsafeDivTwo(a: Double, b: Double): Double = {
    a / b
}
```

If we call our first function with positive real numbers, we'll get the expected result:

##### **Code**
```Scala
unsafeDivOne(UnsafeDivTwo, 12, 2, 3)
```

##### **Output**
```
// res1: Double = 2.0
```

However, as simple as this example is, it can easily fail; if we feed 0 to the parameter B, the result of the expression becomes undefined, and the execution returns infinity.

##### **Code**
```Scala
unsafeDivOne(UnsafeDivTwo, 12, 0, 3)
```

##### **Output**
```
// res1: Double = Infinity
```

Let us redefine our unsafe implementations to safe ones:

##### **Code**
```Scala
// Safe division one
def safeDivOne(SafeDivTwo: (Double, Double) => Option[Double], a: Double, b: Double, d: Double): Option[Double] = {
    if (b != 0 & d != 0) {
        safeDivTwo(a, b).flatMap(result => safeDivTwo(result, d))
    }
    else None
}

// Safe division two
def safeDivTwo(a: Double, b: Double): Option[Double] = {
    if (b != 0) Some(a / b)
    else None
}
```

In this solution, we use the `Option` monad to handle the possibility of a division by zero. `Option` is a container type that represents the presence or absence of a value. It has two subclasses: `Some` and `None`.

`Some` represents a value being present, whereas `None` represents the absence of a value. By using `Option` and the `flatMap` function, we can chain operations and handle the absence of a value elegantly and effectively.

This can be a little confusing, so lets explain what we're doing step-by-step:
1. Define the `safeDivOne` function:
	- It takes a function `safeDivTwo` as a parameter, which has the type `(Double, Double) => Option[Double]`.
	- It also takes three `Double` parameters: `a`, `b`, and `d`.
2. Check if both `b` and `d` are non-zero:
	- If either `b` or `d` is zero, the function returns `None` as the result, indicating that the division cannot be performed.
	- In this case, `None` is used to represent the absence of a valid division result.
3. If both `b` and `d` are non-zero, perform the first division operation:
	- Call the `safeDivTwo` function with `a` and `b` as arguments.
	- This will return an `Option[Double]` representing the result of the first division operation.
	- If the division is valid, the result is wrapped in a `Some`, indicating the presence of a value. Otherwise, it returns `None`.
4. Chain the second division operation using the `flatMap` method:
	- The `flatMap` method is used on the `Option[Double]` returned by the first division operation. It helps in chaining the operations when working with monads like `Option`.
	 - It takes a function as its argument, which receives the inner value of the `Option[Double]` (the result of the first division operation) only if it's a `Some`.
	- The function calls `safeDivTwo` with the result of the first division and `d` as arguments.
	- This will return an `Option[Double]` representing the result of the second division operation, again wrapping the result in a `Some` if the division is valid, or returning `None` otherwise.
5. Return the final result, which is an `Option[Double]` representing the result of both division operations or the absence of a valid result.
6. Define the `safeDivTwo` function:
	- It takes two `Double` parameters: `a` and `b`.
	- It checks if `b` is non-zero.
	- If `b` is non-zero, it returns `Some(a / b)` as the division result, wrapping the value in a `Some` to indicate the presence of a valid result.
	- If `b` is zero, it returns `None` to indicate that the division cannot be performed, representing the absence of a valid result.
7. Call the `safeDivOne` function with the `safeDivTwo` function, `12`, `2`, and `3` as arguments, and store the result in a variable.

We can then call our function with unsafe parameters:

##### **Code**
```Scala
safeDivOne(safeDivTwo, 12, 0, 3)
```

And the output will be what we intended.

##### **Output**
```
// res1: Option[Double] = None
```

Of course, there's no point in making all this effort if the user gets a `None` value as a result.

This is where our next technique, pattern matching, comes into play.


## 4. Recommendations & best practices


## 5. Use cases


---

# Pattern matching and extractors
The concept of **pattern matching** has been used in various forms in different programming languages and systems, but its specific use in functional programming is often attributed to the computer scientist [David Turner](https://en.wikipedia.org/wiki/David_Turner_(computer_scientist)).

Turner also invented the functional programming language [Miranda](https://en.wikipedia.org/wiki/Miranda_(programming_language)), which was one of the first languages to incorporate pattern matching as a core feature. It was introduced in the 1980s and used a syntax for pattern matching that has since become a common feature in many functional programming languages, including [Haskell](), [F#](), and [Scala]().

The concept of **extractors** is also often attributed to David Turner, who introduced them as a feature of the same language.

## 1. Definition
Pattern matching is a powerful technique, where we can.

## 2. Advantages

## 3. Examples
If we recall from our last technique, we were using the `Option` monad to implement two safe division functions that can deal with undefined values *(i.e., division by zero)*.

In this section, we'll add some more functionalities to this implementation.

### 3.1 Handling an undefined operation
We can extend our `safeDivision` functionality by using pattern matching:

##### **Code**
```Scala
def checkDivide(result: Option[Double]) = {
    result match {
    case Some(value) => println(s"Division result: $value")
    case None        => println("Division by zero is not allowed")
    }
}
```

Now, we simply feed our expression:

##### **Code**
```Scala
checkDivide(safeDivOne(safeDivTwo, 12, 2, 3))
checkDivide(safeDivOne(safeDivTwo, 12, 0, 3))
```

##### **Output**
```
// Division result: 2.0
// Division by zero is not allowed
```

## 4. Recommendations & best practices


## 5. Use cases



---

# Lazy evaluation
The concept of **lazy evaluation** has been around for a long time and has been used in various forms in different programming languages and systems. However, the term "*lazy evaluation*" was coined in the 1970s by the computer scientist [Peter J. Landin](https://en.wikipedia.org/wiki/Peter_Landin) in his paper *"[The Next 700 Programming Languages](https://www.cs.cmu.edu/~crary/819-f09/Landin66.pdf)"*.

It was also highly influenced by Daniel Friedman and David Wise in their paper *"[Cons should not evaluate its arguments](https://help.luddy.indiana.edu/techreports/TRNNN.cgi?trnum=TR44)"*.

## 1. Definition


## 2. Advantages


## 3. Examples


## 4. Recommendations & best practices


## 5. Use cases


---

# Implicits and type classes
**Implicits** and **type classes** are two different but closely-related concepts widely used in functional programming languages, particularly in Scala. While the development of these concepts was a collaborative effort among many programmers and researchers, the contributions of [Martin Odersky](https://en.wikipedia.org/wiki/Martin_Odersky), the creator of Scala, were particularly significant.

## 1. Definition


## 2. Advantages


## 3. Examples


## 4. Recommendations & best practices


## 5. Use cases


---

# Continuation-passing style (CPS)
The concept of **CPS** can be traced back to the work of several computer scientists, including [John McCarthy](https://en.wikipedia.org/wiki/John_McCarthy_(computer_scientist)), [Peter Landin](https://en.wikipedia.org/wiki/Peter_Landin), and [Christopher Strachey](https://en.wikipedia.org/wiki/Christopher_Strachey).

However, the specific term "*continuation-passing style*" and its use in programming languages can be attributed to the American computer scientist [Daniel P. Friedman](https://en.wikipedia.org/wiki/Daniel_P._Friedman) and his colleagues. In the early 1970s,

## 1. Definition

## 2. Advantages

## 3. Examples

## 4. Recommendations & best practices

## 5. Use cases

---

# Macros and metaprogramming
The specific use of **macros** as a **metaprogramming** technique is attributed to the computer scientist and programmer [Donald E. Knuth](https://en.wikipedia.org/wiki/Donald_Knuth).

## 1. Definition

## 2. Advantages

## 3. Examples

## 4. Recommendations & best practices

## 5. Use cases

---

# Higher-kinded types
We close this segment with a very interesting and special group of types called **higher-kinded types**. Their use as a feature of functional programming is often attributed to the computer scientist and programming language designer [Philip Wadler](https://en.wikipedia.org/wiki/Philip_Wadler), and were formally introduced in computational theory in the [ML](https://www.cs.nmsu.edu/~rth/cs/cs471/sml.html) language during the late 1970s.

## 1. Definition
Higher-kinded types, also known as type constructors or type-level functions, are a type-level abstraction that allow type constructors (such as lists or trees) to be parameterized by other type constructors.

In simpler terms, higher-kinded types are a way of defining types that can work with other types. Let us imagine a tool that can drill a hole in any kind of material, such as wood, metal, or plastic. This tool would be analogous to a higher-kinded type, since it can work with different types of materials.

In programming, higher-kinded types are used to create types that can work with other types, like lists, maps, and other data structures. This allows these types to be more generic and reusable, and makes it easier to write code that works with different types of data.

## 2. Advantages
As with many elegant forms of abstraction, the advantages for this technique are vast: 
1. **Library Design and Implementation:** Most of the use cases of higher-kinded types are found in library design and implementation. It provides the client more control over the exposed interfaces, while reducing code duplication. [Scalaz](https://github.com/scalaz/scalaz), one of the most popular Scala projects, uses higher-kinded types to extend the core Scala library for functional programming.
2. **Reusability:** Higher-kinded types allow for the creation of more generic and reusable abstractions, making it easier to write code that works with different types of data.
3. **Flexibility:** They also make it easier to create complex data structures and algorithms that can work with different types of data.
4. **Separation of concerns:** They allow for a clear separation of concerns between the data and the operations that work on that data, making code easier to understand and maintain.
5. **Modularity:** Higher-kinded types enable the creation of modular and composable code that can be easily combined and reused in different contexts.
6. **Type safety:** Finally, higher-kinded types can help prevent type errors and make it easier to reason about code by ensuring that types are used correctly and consistently throughout a program.
7. **Polymorphic Containers:** Higher-kinded types are useful when we want to create a container that can hold any type of items; we don’t need a different type for each specific content type.

Let us work on some examples to further clarify.

## 3. Examples
Since higher-kinded types are somewhat of a difficult topic without some prerequisites, we'll stick with an extremely simple case of a higher-kinded type for a specific container type, in our case, a `List` or an `Option`.

### 3.1 Implementing a higher-kinded type for a List
Before any code, we'll explain step-by-step what we will do:
1. **Define the higher-kinded type called Box:** Define a trait or abstract class with a type parameter that itself takes a type parameter. This is our higher-kinded type.
2. **Define how the Box trait should work with Lists:** It defines how the methods in the `Box` trait should behave when working with a `List`. In our case, the `ListBox` class will provide an implementation of the `first` method for a `List`.
3. **Define how the Box type should work with Vectors:** The `VectorBox` class will provide an equivalent implementation for vectors.
4. **Implement a function that can work with instances of both types:** Implement a function `findFirst` that works with instances of our higher-kinded type.

Now that we have a little bit more clarity, we can begin with our implementation:

##### **Code**
```Scala
// 1. Define the higher-kinded type called Box
trait Box[F[_]] {
  def first[A](fa: F[A]): Option[A]
}

// 2. Define how the Box type should work with Lists
class ListBox extends Box[List] {
  def first[A](list: List[A]): Option[A] = list.headOption
}

// 3. Define how the Box type should work with Vectors
class VectorBox extends Box[Vector] {
  def first[A](vector: Vector[A]): Option[A] = vector.headOption
}

// 4. Implement a function findFirst that works with instances of our higher-kinded type
def findFirst[F[_], A](box: Box[F], container: F[A]): Option[A] = {
  box.first(container)
}

// 5. Create an instance of ListBox and use it to find the first element in a list
val listBox = new ListBox()
val myList = List(1, 2, 3)
val firstElementList = findFirst(listBox, myList)

// 6. Create an instance of VectorBox and use it to find the first element in a Vector
val vectorBox = new VectorBox()
val myVector = Vector(4, 5, 6)
val firstElementVector = findFirst(vectorBox, myVector)
```

##### **Code**
```Scala
// Print both values
println(firstElementList)
println(firstElementVector)
```

##### **Output**
```
// Some(1)
// Some(4)
```

We can even go one step further, and introduce a generic implementation of the `Box` trait that can handle different container types based on the type constructor provided. However, we will need to introduce two new concepts, and one curious library called [Cats](https://typelevel.org/cats/) (*yes, there are actual cats in Cats*), aimed at providing abstractions for Scala.

For this, we will first head to our `build.sbt` file and append the following line:

##### **Code**
```Scala
libraryDependencies += "org.typelevel" %% "cats-core" % "2.6.1"
```

So that our entire build file should look like such:

##### **Code**
```Scala
import Dependencies._

ThisBuild / scalaVersion     := "2.12.8"
ThisBuild / version          := "0.1.0-SNAPSHOT"
ThisBuild / organization     := "com.example"
ThisBuild / organizationName := "example"

lazy val root = (project in file("."))
  .settings(
    name := "10-advanced-programming-techniques",
    libraryDependencies += scalaTest % Test,
    libraryDependencies += "org.typelevel" %% "cats-core" % "2.6.1"
  )
```

This should automatically download `Cats` and make it available for import. So, back in our worksheet file, we can include the following:

##### **Code**
```Scala
import cats._
import cats.implicits._
import cats.instances.list._
import cats.instances.vector._
```

Lets get this party started, shall we?

Let us define our generic implementation:

##### **Code**
```Scala
class GenericBox[F[_]: Foldable] extends Box[F] {
  def first[A](container: F[A]): Option[A] = {
    Foldable[F].reduceLeftOption(container)((a, _) => a)
  }
}
```

Where:
- `Foldable` is a typeclass in the `Cats` library that represents data structures that can be folded to a summary value. It provides a set of methods for folding and reducing data structures, such as `foldLeft`, `foldRight`, `reduceLeftOption`, `reduceRightOption`, and more.
- `reduceLeftOption` is a method provided by the `Foldable` typeclass that reduces a container of elements of type `A` to a single value of type `A`. It applies a binary function, which takes two elements of type `A` and returns a single element of type `A`, in a left-associative manner.

So in summary, the combination of `Foldable` with `reduceLeftOption` gets us the first element of a `List` or a `Vector`, which is exactly what we're looking for.

Lastly, we simply need to define our appropriate instances and call the appropriate methods:

##### **Code**
```Scala
// 2. Create an instance of ListBox and use it to find the first element in a list
val genericListBox = new GenericBox[List]
val myList2 = List(1, 2, 3)
val firstElementList2 = genericListBox.first(myList2)

// 3. Create an instance of VectorBox and use it to find the first element in a Vector
val genericVectorBox = new GenericBox[Vector]
val myVector2 = Vector(4, 5, 6)
val firstElementVector2 = genericVectorBox.first(myVector2)
```

##### **Code**
```Scala
println(firstElementList)
println(firstElementVector)
```

##### **Output**
```
// Some(1)
// Some(4)
```

So, where did our drill and materials analogy go in all of this nonsense? Simple:
- `Box` is our marvelous drill.
- `List` is a glass material.
- `Vector` is a stone material.
- `Box` can drill both *(i.e., can get their first element)*:
	- Using different drillbits in our original implementation.
	- Using the "same" drillbit in our last generic implementation.

The interesting thing is that this is just one level of abstraction. We could think that we can keep doing abstractions over traits, and we would be correct. This is precisely the power of higher-kinded types. Additionally, the Cats library provides a wide variety of tools we can use. 

## 4. Recommendations & best practices


## 5. Use cases


---

# Next steps
Scala, and functional programming in general, provides a wide variety of advanced *(and cryptically-named)* techniques and constructs we can make use of. We have to keep in mind that functional programming is heavily-based on lambda calculus, hence, the further we advance, the more mathematical theory will come to surface.

Following up from monads:
- [Monoids](https://www.baeldung.com/scala/monoids-semigroups)
- [Semigroups](https://www.baeldung.com/scala/monoids-semigroups)
- [Functors & Endofunctors](https://www.baeldung.com/scala/functors-functional-programming)
- [Category Theory & Algebraic Structures](https://medium.com/free-code-camp/demistifying-the-monad-in-scala-part-2-a-category-theory-approach-2f0a6d370eff)

Following up from high-order functions:



---

# Conclusions
We've reviewed 10 advanced programming techniques in detail, discussing their importance

---

# References
- Aa


---

# Copyright
Pablo Aguirre, Creative Commons Attribution 4.0 International, All Rights Reserved.